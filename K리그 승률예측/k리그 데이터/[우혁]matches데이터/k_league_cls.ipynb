{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib import font_manager, rc\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "# from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, PowerTransformer, OrdinalEncoder,\n",
    "    OneHotEncoder, FunctionTransformer, PolynomialFeatures, LabelEncoder, MinMaxScaler\n",
    ")\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, RFE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, LinearRegression, Ridge, Lasso,\n",
    "    SGDRegressor, ElasticNet\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, cross_validate,\n",
    "    GridSearchCV, KFold, cross_val_predict\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, mean_squared_error, make_scorer, accuracy_score, log_loss\n",
    ")\n",
    "from sklearn import set_config, datasets\n",
    "from catboost import (\n",
    "    CatBoostRegressor, CatBoostClassifier,\n",
    ")\n",
    "# import category_encoders as ce\n",
    "# from sklearn.pipeline import (\n",
    "#     Pipeline, FeatureUnion, make_pipeline\n",
    "# )\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, StackingClassifier, StackingRegressor,\n",
    "    GradientBoostingRegressor, VotingClassifier, VotingRegressor,\n",
    "    HistGradientBoostingRegressor, GradientBoostingClassifier,\n",
    "    BaggingClassifier, AdaBoostClassifier, RandomForestRegressor,ExtraTreesRegressor\n",
    ")\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# from tpot import TPOTClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import math\n",
    "import optuna\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('matches_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480, 29)"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = df.loc[(df['home_team_goal_count'] != 0) & (df['home_team_result'] == '승')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'home_team_result' 무 -> 승,패로 업데이트, 추가적인 기준 필요함\n",
    "df.loc[(df['home_team_result'] == '무') & (df['home_team_shots_on_target'] >= df['away_team_shots_on_target']), 'home_team_result'] = '승'\n",
    "df.loc[(df['home_team_result'] == '무') & (df['home_team_shots_on_target'] < df['away_team_shots_on_target']), 'home_team_result'] = '패'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature fun\n",
    "def team_encoding(train):\n",
    "    train['home_win'] = train['home_team_result'].apply(lambda x: 1 if x=='승' else 0) # home_win 열 추가, 승리인 경우 1, 아닌 경우 0\n",
    "    dic = {}\n",
    "    # 각 홈팀별 이긴 경기 수를 딕셔너리에 저장\n",
    "    for team in train['home_team_name'].unique():\n",
    "        value = train[train['home_team_name'] == team]['home_win'].sum() \n",
    "        #home_team_name  열에서 고유한 팀 이름을 가져와 각 팀이 홈에서 이긴 경기 수 계산, 이 값을 dic에 저장\n",
    "        dic[team] = value\n",
    "\n",
    "    label_dic={}\n",
    "    # 승리 횧수를 기준으로 오름차순 정렬, 각 팀에 대해 라벨 부여, 승리 횟수가 적은 팀부터 0,1,2 의 라벨을 부여\n",
    "    for idx, (team, _) in enumerate(sorted(dic.items(), key= lambda x: x[1])):\n",
    "        label_dic[team] = idx\n",
    "    \n",
    "    return label_dic\n",
    "\n",
    "\n",
    "''' 홈팀 득점 이동평균 계산 함수 '''\n",
    "\n",
    "def homeGoal_day_mean(train, test, day):\n",
    "    train[f'home_Goal_{day}_mean'] = -1  # 초기값 -1로 설정\n",
    "    test[f'home_Goal_{day}_mean'] = -1\n",
    "    \n",
    "    teams = train['home_team_name'].unique()\n",
    "    for team in tqdm(teams): # train에서 고유 팀 이름을 가져오고 이를 시각적으로 표시해줌 : tqdm\n",
    "        team_df = train[train['home_team_name'] == team]\n",
    "        # 롤링 윈도우 크기 설정\n",
    "        ch_day = len(team_df) if len(team_df) < day else day # 팀의 경기 수가 주어진 day 보다 적으면, 경기 수 만큼의 윈도우 크기 사용\n",
    "        idx = team_df['home_team_goal_count'].rolling(ch_day).mean().index.values # 롤링 윈도우 평균 계산\n",
    "        val = team_df['home_team_goal_count'].rolling(ch_day).mean().values\n",
    "        train[f'home_Goal_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['home_team_name'] == team].index\n",
    "        test[f'home_Goal_{day}_mean'].loc[test_idx] = val[-1]\n",
    "    # 결측값 처리\n",
    "    train[f'home_Goal_{day}_mean'] = train[f'home_Goal_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "''' 원정팀 득점 이동평균 계산 함수 '''\n",
    "\n",
    "def awayGoal_day_mean(train, test, day):\n",
    "    # 초기값 설정\n",
    "    train[f'away_Goal_{day}_mean'] = -1\n",
    "    test[f'away_Goal_{day}_mean'] = -1\n",
    "    \n",
    "    teams = train['away_team_name'].unique()\n",
    "    for team in tqdm(teams):\n",
    "        team_df = train[train['away_team_name'] == team]\n",
    "        # 롤링 윈도우 크기 설정\n",
    "        ch_day = len(team_df) if len(team_df) < day else day\n",
    "        idx = team_df['away_team_goal_count'].rolling(ch_day).mean().index.values\n",
    "        val = team_df['away_team_goal_count'].rolling(ch_day).mean().values\n",
    "        train[f'away_Goal_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['away_team_name'] == team].index\n",
    "        test[f'away_Goal_{day}_mean'].loc[test_idx] = val[-1]\n",
    "    # 결측값 처리\n",
    "    train[f'away_Goal_{day}_mean'] = train[f'away_Goal_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "# '''홈팀 승리율 평균 계산 함수'''\n",
    "\n",
    "# def homeWin_day_mean(train, test, day):\n",
    "#     train[f'home_winRate_{day}_mean'] = -1\n",
    "#     test[f'home_winRate_{day}_mean'] = -1\n",
    "#     train['win'] = train['home_team_result'].apply(lambda x: 1 if x == '승' else 0)\n",
    "\n",
    "#     teams = train['home_team_name'].unique()\n",
    "#     for team in tqdm(teams):\n",
    "#         team_df = train[train['home_team_name'] == team]\n",
    "#         ch_day = len(team_df) if len(team_df) < day else day\n",
    "#         idx = team_df['win'].rolling(ch_day).mean().index.values\n",
    "#         val = team_df['win'].rolling(ch_day).mean().values\n",
    "#         train[f'home_winRate_{day}_mean'].loc[idx] = val\n",
    "#         test_idx = test[test['home_team_name'] == team].index\n",
    "#         test[f'home_winRate_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "#     train.drop(columns=['win'], inplace=True)\n",
    "\n",
    "#     train[f'home_winRate_{day}_mean'] = train[f'home_winRate_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "# '''원정팀 승리율 평균 계산 함수'''\n",
    "\n",
    "# def awayWin_day_mean(train, test, day):\n",
    "\n",
    "#     train[f'away_winRate_{day}_mean'] = -1\n",
    "#     test[f'away_winRate_{day}_mean'] = -1\n",
    "#     train['win'] = train['home_team_result'].apply(lambda x: 1 if x == '패' else 0)\n",
    "    \n",
    "#     teams = train['away_team_name'].unique()\n",
    "#     for team in tqdm(teams):\n",
    "#         team_df = train[train['away_team_name'] == team]\n",
    "\n",
    "#         ch_day = len(team_df) if len(team_df) < day else day\n",
    "#         idx = team_df['win'].rolling(ch_day).mean().index.values\n",
    "#         val = team_df['win'].rolling(ch_day).mean().values\n",
    "#         train[f'away_winRate_{day}_mean'].loc[idx] = val\n",
    "#         test_idx = test[test['away_team_name'] == team].index\n",
    "#         test[f'away_winRate_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "#     train.drop(columns=['win'], inplace=True)\n",
    "\n",
    "#     train[f'away_winRate_{day}_mean'] = train[f'away_winRate_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''홈팀 평균 계산 함수'''\n",
    "\n",
    "def home_day_mean(train, test, columns, day):\n",
    "    for column in tqdm(columns):\n",
    "        teams = train['home_team_name'].values\n",
    "        train[f'home_{column}_{day}_mean'] = -1\n",
    "        test[f'home_{column}_{day}_mean'] = -1\n",
    "\n",
    "        for team in tqdm(teams):\n",
    "            team_df = train[train['home_team_name'] == team]\n",
    "            idx = team_df[column].rolling(day).mean().index.values\n",
    "            val = team_df[column].rolling(day).mean().values\n",
    "            train[f'home_{column}_{day}_mean'].loc[idx] = val\n",
    "            test_idx = test[test['home_team_name'] == team].index\n",
    "            test[f'home_{column}_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "        train[f'home_{column}_{day}_mean'] = train[f'home_{column}_{day}_mean'].fillna(0)\n",
    "        test[f'home_{column}_{day}_mean'] = test[f'home_{column}_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''원정팀 평균 계산 함수'''\n",
    "\n",
    "def away_day_mean(train, test, columns, day):\n",
    "    for column in tqdm(columns):\n",
    "        teams = train['away_team_name'].values\n",
    "        train[f'away_{column}_{day}_mean'] = -1\n",
    "        test[f'away_{column}_{day}_mean'] = -1\n",
    "\n",
    "        for team in tqdm(teams):\n",
    "            team_df = train[train['away_team_name'] == team]\n",
    "            idx = team_df[column].rolling(day).mean().index.values\n",
    "            val = team_df[column].rolling(day).mean().values\n",
    "            train[f'away_{column}_{day}_mean'].loc[idx] = val\n",
    "            test_idx = test[test['away_team_name'] == team].index\n",
    "            test[f'away_{column}_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "        train[f'away_{column}_{day}_mean'] = train[f'away_{column}_{day}_mean'].fillna(0)\n",
    "        test[f'away_{column}_{day}_mean'] = test[f'away_{column}_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''전처리 함수'''\n",
    "\n",
    "def preprocessing(train, test):\n",
    "    # 년과 월일로 나누기\n",
    "    train['date_GMT'] = train['date_GMT'].dt.strftime('%Y%m%d')\n",
    "    test['date_GMT'] = test['date_GMT'].dt.strftime('%Y%m%d')\n",
    "    \n",
    "    train['year'] = train['date_GMT'].apply(lambda x : int(x[0:4]))\n",
    "    train['date'] = train['date_GMT'].apply(lambda x : int(x[4:10]))\n",
    "\n",
    "    test['year'] = test['date_GMT'].apply(lambda x : int(x[0:4]))\n",
    "    test['date'] = test['date_GMT'].apply(lambda x : int(x[4:10]))\n",
    "\n",
    "    # train.drop(columns=['date_GMT'], inplace=True)\n",
    "    # test.drop(columns=['date_GMT'], inplace=True)\n",
    "\n",
    "    # # 팀 인코딩 적용   # 위에서 적용 했음\n",
    "    # label_dic = dic\n",
    "    # train['home_team_name'] = train['home_team_name'].apply(lambda x: label_dic[x])\n",
    "    # train['away_team_name'] = train['away_team_name'].apply(lambda x: label_dic[x])\n",
    "    # test['home_team_name'] = test['home_team_name'].apply(lambda x: label_dic[x])\n",
    "    # test['away_team_name'] = test['away_team_name'].apply(lambda x: label_dic[x])\n",
    "\n",
    "    # # 5일간 홈팀 승리 비율 계산    ### 이거 쓰레기인듯\n",
    "    # homeWin_day_mean(train, test, 5)\n",
    "    # # 5일간 원정팀 승리 비율 계산\n",
    "    # awayWin_day_mean(train, test, 5)\n",
    "\n",
    "    # 5일간 홈팀 평균 득점 계산\n",
    "    homeGoal_day_mean(train, test, 5)\n",
    "\n",
    "    # 5일간 원정팀 평균 득점 계산\n",
    "    awayGoal_day_mean(train, test, 5)\n",
    "\n",
    "    # 불필요한 컬럼 제거\n",
    "    train = train.drop(columns=['index','home_team_goal_count','away_team_goal_count','game_points'])\n",
    "    test = test.drop(columns=['index','home_team_goal_count','away_team_goal_count','home_team_result','game_points'])\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y\n",
    "X = df.drop(columns=['away_team_possession'])  \n",
    "y = df['home_team_result']\n",
    "# split_index = 1796 # 2021년도까지의 index\n",
    "# train = X.iloc[:split_index]\n",
    "# test = X.iloc[split_index:]\n",
    "# y_train = y.iloc[:split_index]\n",
    "# y_test = y.iloc[split_index:]\n",
    "\n",
    "# team_name 인코딩\n",
    "cat = ['home_team_name','away_team_name']\n",
    "le = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, dtype=int)\n",
    "X[cat] = le.fit_transform(X[cat])\n",
    "\n",
    "# 승무패 인코딩\n",
    "lec = LabelEncoder()\n",
    "lec.fit(X['home_team_result'])\n",
    "y = lec.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 413.19it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 491.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1984, 28) (496, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train,Test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42) ## 이 방법에 의문을 품는 바\n",
    "\n",
    "X_train, X_val= preprocessing(X_train, X_val)\n",
    "X_val_idx = X_val.index.values\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홈팀과 원정팀의 공격 효율성을 계산한 피쳐 생성\n",
    "X_train['home_attack_efficiency'] = X_train['home_Goal_5_mean'] * X_train['home_team_shots_on_target']\n",
    "X_train['away_attack_efficiency'] = X_train['away_Goal_5_mean'] * X_train['away_team_shots_on_target']\n",
    "\n",
    "# 홈팀과 원정팀의 공격 효율성 차이를 나타내는 피쳐 생성\n",
    "X_train['attack_efficiency_difference'] = X_train['home_attack_efficiency'] - X_train['away_attack_efficiency']\n",
    "\n",
    "# 홈팀과 원정팀의 전반 골 수 차이를 나타내는 피쳐 생성\n",
    "X_train['goal_count_diff'] = X_train['home_team_goal_count_half_time'] - X_train['away_team_goal_count_half_time']\n",
    "\n",
    "# 최근 5경기 평균 득점의 표준 편차를 나타내는 피쳐 생성\n",
    "X_train['home_Goal_5_std'] = X_train['home_Goal_5_mean'].rolling(window=5).std()\n",
    "X_train['away_Goal_5_std'] = X_train['away_Goal_5_mean'].rolling(window=5).std()\n",
    "\n",
    "# 결측값을 0으로 대체\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "# 테스트 데이터에도 동일한 피쳐 생성\n",
    "X_val['home_attack_efficiency'] = X_val['home_Goal_5_mean'] * X_val['home_team_shots_on_target']\n",
    "X_val['away_attack_efficiency'] = X_val['away_Goal_5_mean'] * X_val['away_team_shots_on_target']\n",
    "X_val['attack_efficiency_difference'] = X_val['home_attack_efficiency'] - X_val['away_attack_efficiency']\n",
    "X_val['goal_count_diff'] = X_val['home_team_goal_count_half_time'] - X_val['away_team_goal_count_half_time']\n",
    "X_val['home_Goal_5_std'] = X_val['home_Goal_5_mean'].rolling(window=5).std()\n",
    "X_val['away_Goal_5_std'] = X_val['away_Goal_5_mean'].rolling(window=5).std()\n",
    "X_val = X_val.fillna(0)\n",
    "\n",
    "# 학습 데이터에서 목표 변수 'home_team_result' 컬럼 제거\n",
    "X_train.drop(columns = ['home_team_result'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "cat = ['home_team_name','away_team_name']\n",
    "\n",
    "num_features = list(set(X_train.columns) - set(cat))\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_val[num_features] = scaler.transform(X_val[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0: 10000, 1: 10000})\n",
      "Original training set shape: (1984, 33)\n",
      "Resampled training set shape: (20000, 33)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# SMOTE 객체 생성 (각 클래스의 샘플 수를 1000개로 설정)\n",
    "smote = SMOTE(sampling_strategy={0: 10000, 1: 10000}, random_state=42)\n",
    "\n",
    "# SMOTE-Tomek 객체 생성\n",
    "smote_tomek = SMOTETomek(smote=smote, random_state=42)\n",
    "\n",
    "# 오버샘플링 및 언더샘플링 적용\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# 각 클래스 비율 확인\n",
    "print(f\"Resampled class distribution: {Counter(y_train_resampled)}\")\n",
    "print(f\"Original training set shape: {X_train.shape}\")\n",
    "print(f\"Resampled training set shape: {X_train_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycaret.classification import *\n",
    "\n",
    "# setup_clf = setup(data = X_train, target = y_train, session_id = 42)\n",
    "# model = compare_models(sort = 'Accuracy', fold = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tune = tune_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(best_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7681451612903226\n",
      "Filtered SHAP Importances:\n",
      "                      column_name  shap_importance\n",
      "29  attack_efficiency_difference         1.626208\n",
      "22                5_games_result         1.532867\n",
      "7      home_team_shots_on_target         1.273232\n",
      "8      away_team_shots_on_target         1.154204\n",
      "30               goal_count_diff         1.052740\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import shap\n",
    "SHAP_THRESHOLD = 1.0\n",
    "\n",
    "# feature_names dimension 조정\n",
    "X_train_col = X_train.columns\n",
    "feature_names = X_train_col.to_numpy()\n",
    "\n",
    "# 모델 학습\n",
    "model = xgb.XGBClassifier().fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 모델 예측 및 평가\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# SHAP 값 계산\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "# SHAP 값 요약\n",
    "if isinstance(shap_values, list):  # shap_values가 리스트일 경우 (XGBoost >= 1.0.0)\n",
    "    shap_values = shap_values[1]\n",
    "\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame({'column_name': feature_names, 'shap_importance': shap_sum})\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "\n",
    "# 중요도 임계값 적용 (선택 사항)\n",
    "importance_df_filtered = importance_df[importance_df['shap_importance'] > SHAP_THRESHOLD]\n",
    "print(\"Filtered SHAP Importances:\\n\", importance_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된(SHAP_THRESHOLD) Shap feature 중요도 이상인 것만 선택\n",
    "features_selected = importance_df.query('shap_importance > @SHAP_THRESHOLD').column_name.tolist()\n",
    "shap_xgb_X_train_resampled = X_train_resampled[features_selected]\n",
    "shap_xgb_X_val = X_val[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LightGBM 모델 학습\n",
    "# model = lgb.LGBMClassifier().fit(X_train_resampled, y_train_resampled)\n",
    "# SHAP_THRESHOLD = 0.3\n",
    "\n",
    "# # 모델 예측 및 평가\n",
    "# y_pred = model.predict(X_val)\n",
    "# print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# # SHAP 값 계산\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "# shap_sum = np.abs(shap_values).mean(axis=1)[1,:]\n",
    "# importance_df = pd.DataFrame([X_val.columns.tolist(), shap_sum.tolist()]).T\n",
    "# importance_df.columns = ['column_name', 'shap_importance']\n",
    "# importance_df = importance_df.sort_values('shap_importance', ascending=False);\n",
    "# importance_df\n",
    "\n",
    "# # SHAP 값 데이터프레임 생성 (각 피쳐별 SHAP 값)\n",
    "# shap_values_df = pd.DataFrame(shap_values[1], columns=X_val.columns)\n",
    "# shap_values_df\n",
    "\n",
    "# # SHAP 값의 평균 절대값 계산\n",
    "# shap_abs_mean = pd.DataFrame(shap_values[1], columns=X_val.columns).abs().mean().sort_values(ascending=False)\n",
    "\n",
    "# # SHAP 값 평균 절대값 시각화\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# shap_abs_mean.plot(kind='barh')\n",
    "# plt.title(\"Mean Absolute SHAP Values for Features\")\n",
    "# plt.xlabel(\"Mean Absolute SHAP Value\")\n",
    "# plt.ylabel(\"Features\")\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 지정된(SHAP_THRESHOLD) Shap feature 중요도 이상인 것만 선택\n",
    "# features_selected = importance_df.query('shap_importance > @SHAP_THRESHOLD').column_name.tolist()\n",
    "# shap_lgbm_X_train_resampled = X_train_resampled[features_selected]\n",
    "# shap_lgbm_X_val = X_val[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oputna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgboostclassifier\n",
    "# import optuna\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# def xgb_objective(trial):\n",
    "#     # 하이퍼파라미터 범위 설정\n",
    "#     max_depth = trial.suggest_int('max_depth', 3, 7)  # max_depth의 범위를 줄임\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 50, 200)  # n_estimators의 범위를 줄임\n",
    "#     subsample = trial.suggest_float('subsample', 0.5, 0.9)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 0.9)\n",
    "#     min_child_weight = trial.suggest_int('min_child_weight', 4, 10)  # 추가\n",
    "#     gamma = trial.suggest_float('gamma', 0, 5)  # 추가\n",
    "    \n",
    "#     # XGBClassifier 모델 정의\n",
    "#     clf = XGBClassifier(\n",
    "#         max_depth=max_depth,\n",
    "#         learning_rate=learning_rate,\n",
    "#         n_estimators=n_estimators,\n",
    "#         subsample=subsample,\n",
    "#         colsample_bytree=colsample_bytree,\n",
    "#         min_child_weight=min_child_weight,  # 추가\n",
    "#         gamma=gamma,  # 추가\n",
    "#         use_label_encoder=False,\n",
    "#         eval_metric='logloss'\n",
    "#     )\n",
    "    \n",
    "#     # 교차 검증 점수 계산\n",
    "#     scores = cross_val_score(clf, shap_xgb_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "#     return scores.mean()\n",
    "\n",
    "# # Optuna 스터디 생성 및 최적화\n",
    "# xgb_study = optuna.create_study(direction='maximize')\n",
    "# xgb_study.optimize(xgb_objective, n_trials=50)  # 최적화 반복 횟수는 필요에 따라 조절\n",
    "\n",
    "# # 최적 하이퍼파라미터 출력\n",
    "# xgb_best_params = xgb_study.best_params\n",
    "# print(' ')\n",
    "# print(xgb_study.best_value)\n",
    "# print(xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_logis=xgb.XGBClassifier(**xgb_best_params)\n",
    "# # model_logis=xgb.XGBClassifier(max_depth= 4, learning_rate= 0.00020353095689003422, n_estimators= 229, subsample= 0.5217582675029752, colsample_bytree= 0.5421399627551824)\n",
    "# model_logis.fit(shap_xgb_X_train_resampled, y_train_resampled)\n",
    "# y_pred = model_logis.predict(shap_xgb_X_val)\n",
    "\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy=\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LogisticRegression\n",
    "# def logreg_objective(trial):\n",
    "\n",
    "#     r = trial.suggest_float('l1_ratio', 0.3, 0.8, log=False)  # 범위를 0.1에서 0.9로 좁힘\n",
    "#     c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "#     max_iter = trial.suggest_int('max_iter', 500, 2000, step=500)  # max_iter 튜닝 추가\n",
    "    \n",
    "#     clf =  LogisticRegression(max_iter=max_iter, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "#     scores = cross_val_score(clf, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "#     return scores.mean()\n",
    "    \n",
    "# logreg_study = optuna.create_study(direction='maximize')\n",
    "# logreg_study.optimize(logreg_objective, n_trials=20)\n",
    "\n",
    "# logreg_best_params = logreg_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_logis=LogisticRegression(**logreg_best_params)\n",
    "# model_logis.fit(X_train_resampled,y_train_resampled)\n",
    "# y_pred = model_logis.predict(X_val)\n",
    "\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-10 12:55:42,181] A new study created in memory with name: no-name-717aed15-02c8-4c91-8f42-dd9b62266221\n",
      "[I 2024-07-10 12:55:42,253] Trial 0 finished with value: 0.932846304092482 and parameters: {'alpha': 1.1191600975756728}. Best is trial 0 with value: 0.932846304092482.\n",
      "[I 2024-07-10 12:55:42,318] Trial 1 finished with value: 0.9328464540685001 and parameters: {'alpha': 1.179167634827491}. Best is trial 1 with value: 0.9328464540685001.\n",
      "[I 2024-07-10 12:55:42,400] Trial 2 finished with value: 0.9328456743084064 and parameters: {'alpha': 0.00191865695861402}. Best is trial 1 with value: 0.9328464540685001.\n",
      "[I 2024-07-10 12:55:42,467] Trial 3 finished with value: 0.9331814829247089 and parameters: {'alpha': 600.8909258956717}. Best is trial 3 with value: 0.9331814829247089.\n",
      "[I 2024-07-10 12:55:42,538] Trial 4 finished with value: 0.9328491239008206 and parameters: {'alpha': 3.6139080246439974}. Best is trial 3 with value: 0.9331814829247089.\n",
      "[I 2024-07-10 12:55:42,632] Trial 5 finished with value: 0.9328456443204027 and parameters: {'alpha': 2.72220965681775e-05}. Best is trial 3 with value: 0.9331814829247089.\n",
      "[I 2024-07-10 12:55:42,736] Trial 6 finished with value: 0.9328685941071573 and parameters: {'alpha': 22.04692450287612}. Best is trial 3 with value: 0.9331814829247089.\n",
      "[I 2024-07-10 12:55:42,831] Trial 7 finished with value: 0.9329024366312187 and parameters: {'alpha': 62.24144373087745}. Best is trial 3 with value: 0.9331814829247089.\n",
      "[I 2024-07-10 12:55:42,898] Trial 8 finished with value: 0.9328456443204027 and parameters: {'alpha': 0.006834062740249614}. Best is trial 3 with value: 0.9331814829247089.\n",
      "[I 2024-07-10 12:55:42,981] Trial 9 finished with value: 0.9328456143323991 and parameters: {'alpha': 0.004846433924527952}. Best is trial 3 with value: 0.9331814829247089.\n",
      "[I 2024-07-10 12:55:43,095] Trial 10 finished with value: 0.9332951328863487 and parameters: {'alpha': 975.6013050559234}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,200] Trial 11 finished with value: 0.9331486010607625 and parameters: {'alpha': 530.2871534973277}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,284] Trial 12 finished with value: 0.9332745786478819 and parameters: {'alpha': 875.2799786400213}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,367] Trial 13 finished with value: 0.9331882931535261 and parameters: {'alpha': 623.9168921043808}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,448] Trial 14 finished with value: 0.9328843450090476 and parameters: {'alpha': 39.265009271294865}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,531] Trial 15 finished with value: 0.9328458842244315 and parameters: {'alpha': 0.11673547450785543}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,615] Trial 16 finished with value: 0.932915636428803 and parameters: {'alpha': 80.12504173388898}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,714] Trial 17 finished with value: 0.9328536242613605 and parameters: {'alpha': 8.683793829420157}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,798] Trial 18 finished with value: 0.9328455543563919 and parameters: {'alpha': 1.3291919860121947e-05}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,885] Trial 19 finished with value: 0.932845614260399 and parameters: {'alpha': 0.25540841490476635}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:43,982] Trial 20 finished with value: 0.9329601907541504 and parameters: {'alpha': 149.01677489264029}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,084] Trial 21 finished with value: 0.9332714580595073 and parameters: {'alpha': 862.6158141690771}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,182] Trial 22 finished with value: 0.9329867411533367 and parameters: {'alpha': 212.60935827880823}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,269] Trial 23 finished with value: 0.9332428664600757 and parameters: {'alpha': 778.0526663731322}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,348] Trial 24 finished with value: 0.9328627743104586 and parameters: {'alpha': 16.899546049328983}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,452] Trial 25 finished with value: 0.9328456143323992 and parameters: {'alpha': 0.00025564822667212484}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,548] Trial 26 finished with value: 0.9329690105752088 and parameters: {'alpha': 168.08230420065416}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,635] Trial 27 finished with value: 0.9328523942492128 and parameters: {'alpha': 7.648511375894849}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,737] Trial 28 finished with value: 0.9328457942604208 and parameters: {'alpha': 0.022590611918241393}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,834] Trial 29 finished with value: 0.9328475337086295 and parameters: {'alpha': 2.1725479218363737}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:44,936] Trial 30 finished with value: 0.9328459742964424 and parameters: {'alpha': 0.624244447892109}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:45,053] Trial 31 finished with value: 0.9332635973505639 and parameters: {'alpha': 840.704834362423}. Best is trial 10 with value: 0.9332951328863487.\n",
      "[I 2024-07-10 12:55:45,179] Trial 32 finished with value: 0.9333005927910039 and parameters: {'alpha': 998.1900515438538}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:45,271] Trial 33 finished with value: 0.9329951723543486 and parameters: {'alpha': 226.18329951209893}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:45,349] Trial 34 finished with value: 0.9332987328867808 and parameters: {'alpha': 987.2896579586491}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:45,432] Trial 35 finished with value: 0.9329002761989594 and parameters: {'alpha': 57.52818527964869}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:45,513] Trial 36 finished with value: 0.9330281450823059 and parameters: {'alpha': 282.10312140763125}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:45,601] Trial 37 finished with value: 0.9328717443235353 and parameters: {'alpha': 25.314624283485298}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:45,687] Trial 38 finished with value: 0.9329486693487675 and parameters: {'alpha': 125.36973072462477}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:45,763] Trial 39 finished with value: 0.9328456743084064 and parameters: {'alpha': 0.00033270948744269996}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:45,882] Trial 40 finished with value: 0.9330644175706592 and parameters: {'alpha': 349.0851058564793}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,001] Trial 41 finished with value: 0.9332930025140932 and parameters: {'alpha': 968.5467613785632}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,081] Trial 42 finished with value: 0.9330683183151273 and parameters: {'alpha': 359.10595055062475}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,183] Trial 43 finished with value: 0.9332836410369695 and parameters: {'alpha': 915.6936074329546}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,263] Trial 44 finished with value: 0.9329058564156293 and parameters: {'alpha': 69.38992361921706}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,350] Trial 45 finished with value: 0.9332929722380894 and parameters: {'alpha': 953.4988592265082}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,434] Trial 46 finished with value: 0.9328566844057279 and parameters: {'alpha': 10.439858319813782}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,517] Trial 47 finished with value: 0.9328785847203562 and parameters: {'alpha': 33.57652460050497}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,598] Trial 48 finished with value: 0.9329389489156008 and parameters: {'alpha': 112.11060141772724}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,683] Trial 49 finished with value: 0.9330810695166575 and parameters: {'alpha': 381.7663939976363}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,752] Trial 50 finished with value: 0.9330692781112425 and parameters: {'alpha': 362.2656867724985}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,848] Trial 51 finished with value: 0.9331579021298787 and parameters: {'alpha': 546.6084110464672}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:46,931] Trial 52 finished with value: 0.9332693878072589 and parameters: {'alpha': 855.9616405746157}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,037] Trial 53 finished with value: 0.9329480695886955 and parameters: {'alpha': 121.12738353814707}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,164] Trial 54 finished with value: 0.9332919519259669 and parameters: {'alpha': 948.855715284566}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,284] Trial 55 finished with value: 0.932998382618734 and parameters: {'alpha': 232.85282320545716}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,407] Trial 56 finished with value: 0.9328920552739728 and parameters: {'alpha': 47.0411666794183}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,512] Trial 57 finished with value: 0.9332987627667841 and parameters: {'alpha': 991.5184669116326}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,599] Trial 58 finished with value: 0.9331248990539178 and parameters: {'alpha': 475.8960557501809}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,683] Trial 59 finished with value: 0.9329476197326413 and parameters: {'alpha': 120.62188627803218}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,769] Trial 60 finished with value: 0.9328486738287664 and parameters: {'alpha': 3.473879064791267}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,852] Trial 61 finished with value: 0.9332938428621939 and parameters: {'alpha': 973.5489682891871}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:47,932] Trial 62 finished with value: 0.9330882086415144 and parameters: {'alpha': 400.49743599664055}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,017] Trial 63 finished with value: 0.9329804109485771 and parameters: {'alpha': 190.33432975788907}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,104] Trial 64 finished with value: 0.93315916169803 and parameters: {'alpha': 548.7758331730953}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,183] Trial 65 finished with value: 0.9329132065725113 and parameters: {'alpha': 77.29531409703704}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,282] Trial 66 finished with value: 0.9328457642364172 and parameters: {'alpha': 0.04458660306357106}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,368] Trial 67 finished with value: 0.9329914221258986 and parameters: {'alpha': 220.01167000869208}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,450] Trial 68 finished with value: 0.9331610213142532 and parameters: {'alpha': 558.4607981871218}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,536] Trial 69 finished with value: 0.9332931821181146 and parameters: {'alpha': 964.0068834356837}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,602] Trial 70 finished with value: 0.9328456443204027 and parameters: {'alpha': 0.0010096490839792045}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,695] Trial 71 finished with value: 0.933292912370082 and parameters: {'alpha': 967.2726883315769}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,780] Trial 72 finished with value: 0.9330264644941041 and parameters: {'alpha': 274.34835572037656}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,866] Trial 73 finished with value: 0.9331727519876608 and parameters: {'alpha': 581.8076183507139}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:48,953] Trial 74 finished with value: 0.9329724306836192 and parameters: {'alpha': 174.4159166362853}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,035] Trial 75 finished with value: 0.9331434700881468 and parameters: {'alpha': 514.7160092483255}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,116] Trial 76 finished with value: 0.9329208269814261 and parameters: {'alpha': 87.16500048329104}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,201] Trial 77 finished with value: 0.9332952529463631 and parameters: {'alpha': 976.0392141427142}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,283] Trial 78 finished with value: 0.933031295550684 and parameters: {'alpha': 287.91297296577324}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,364] Trial 79 finished with value: 0.9328456143323991 and parameters: {'alpha': 4.854623653717547e-05}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,451] Trial 80 finished with value: 0.9328634042745342 and parameters: {'alpha': 17.256656136046168}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,553] Trial 81 finished with value: 0.9332134652565472 and parameters: {'alpha': 675.4389619604126}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,644] Trial 82 finished with value: 0.9332972327306006 and parameters: {'alpha': 982.4243156472705}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,733] Trial 83 finished with value: 0.9330672376309977 and parameters: {'alpha': 355.0989092097187}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,816] Trial 84 finished with value: 0.9329749803119253 and parameters: {'alpha': 180.33383340231674}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,901] Trial 85 finished with value: 0.9331702019273549 and parameters: {'alpha': 576.1049226540407}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:49,981] Trial 86 finished with value: 0.9332873611334159 and parameters: {'alpha': 927.2082654679718}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,069] Trial 87 finished with value: 0.9328457942964207 and parameters: {'alpha': 0.3434088249675025}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,150] Trial 88 finished with value: 0.9330342655510405 and parameters: {'alpha': 295.43333644611647}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,221] Trial 89 finished with value: 0.9331015887991202 and parameters: {'alpha': 433.76804134428954}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,314] Trial 90 finished with value: 0.9329538910413943 and parameters: {'alpha': 137.91413546287225}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,379] Trial 91 finished with value: 0.9332935121301541 and parameters: {'alpha': 962.114182118778}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,479] Trial 92 finished with value: 0.9332999927789319 and parameters: {'alpha': 995.9247571148098}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,578] Trial 93 finished with value: 0.9331897030936953 and parameters: {'alpha': 626.6997919648472}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,666] Trial 94 finished with value: 0.9330868589293525 and parameters: {'alpha': 397.4396944048764}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,782] Trial 95 finished with value: 0.9331999332869233 and parameters: {'alpha': 646.4730155059067}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,868] Trial 96 finished with value: 0.9328457342844135 and parameters: {'alpha': 0.007601957014258858}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:50,953] Trial 97 finished with value: 0.9330337557549792 and parameters: {'alpha': 292.5868998146955}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,032] Trial 98 finished with value: 0.932927158518186 and parameters: {'alpha': 97.64621956931656}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,113] Trial 99 finished with value: 0.93329381237019 and parameters: {'alpha': 966.5809083819705}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,198] Trial 100 finished with value: 0.9328942459462359 and parameters: {'alpha': 51.4462680924458}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,286] Trial 101 finished with value: 0.9332914719019093 and parameters: {'alpha': 947.7114331556108}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,368] Trial 102 finished with value: 0.9331999332869233 and parameters: {'alpha': 646.5363518559312}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,447] Trial 103 finished with value: 0.9330014430511012 and parameters: {'alpha': 238.0654832936015}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,531] Trial 104 finished with value: 0.9330918392779503 and parameters: {'alpha': 406.0360367272003}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,601] Trial 105 finished with value: 0.9331924327580229 and parameters: {'alpha': 633.4824154881376}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,716] Trial 106 finished with value: 0.9332934520101469 and parameters: {'alpha': 963.1147153830034}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,821] Trial 107 finished with value: 0.9331282000743141 and parameters: {'alpha': 482.13621425310896}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:51,918] Trial 108 finished with value: 0.932960280682161 and parameters: {'alpha': 149.10526460246427}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:52,004] Trial 109 finished with value: 0.9330067540597385 and parameters: {'alpha': 246.25748812524213}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:52,150] Trial 110 finished with value: 0.9328463940564928 and parameters: {'alpha': 1.155671077005059}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:52,233] Trial 111 finished with value: 0.9332345572270785 and parameters: {'alpha': 747.4976395794914}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:52,320] Trial 112 finished with value: 0.9332931819741145 and parameters: {'alpha': 963.3250046092021}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:52,397] Trial 113 finished with value: 0.9330938797941952 and parameters: {'alpha': 420.1329943929918}. Best is trial 32 with value: 0.9333005927910039.\n",
      "[I 2024-07-10 12:55:52,481] Trial 114 finished with value: 0.9333007127070183 and parameters: {'alpha': 998.1068287258154}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:52,569] Trial 115 finished with value: 0.9332167965889471 and parameters: {'alpha': 694.2951357432299}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:52,652] Trial 116 finished with value: 0.9330582072819137 and parameters: {'alpha': 335.616667269054}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:52,736] Trial 117 finished with value: 0.9329811310206635 and parameters: {'alpha': 194.9937886813372}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:52,844] Trial 118 finished with value: 0.9331375597514372 and parameters: {'alpha': 501.3493858561402}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:52,954] Trial 119 finished with value: 0.9332214768055088 and parameters: {'alpha': 708.5977562340271}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,047] Trial 120 finished with value: 0.9330581771859103 and parameters: {'alpha': 335.55939452034534}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,117] Trial 121 finished with value: 0.9332866410973294 and parameters: {'alpha': 924.6835661840179}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,214] Trial 122 finished with value: 0.9331303296545697 and parameters: {'alpha': 486.25626450075185}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,296] Trial 123 finished with value: 0.9332960328144567 and parameters: {'alpha': 976.5641123920533}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,369] Trial 124 finished with value: 0.9332155363367959 and parameters: {'alpha': 686.2775927019014}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,455] Trial 125 finished with value: 0.933004173795429 and parameters: {'alpha': 241.63974975872728}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,545] Trial 126 finished with value: 0.9331001795069511 and parameters: {'alpha': 428.95057574840575}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,616] Trial 127 finished with value: 0.933232576974841 and parameters: {'alpha': 743.8746785106161}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,714] Trial 128 finished with value: 0.9332910519978589 and parameters: {'alpha': 942.7596632621601}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,820] Trial 129 finished with value: 0.9329695806712772 and parameters: {'alpha': 170.19671849314545}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:53,920] Trial 130 finished with value: 0.9331519319971623 and parameters: {'alpha': 537.4792662564251}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,044] Trial 131 finished with value: 0.9332864309293044 and parameters: {'alpha': 923.810338914118}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,161] Trial 132 finished with value: 0.9332988830427987 and parameters: {'alpha': 990.4350591937682}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,247] Trial 133 finished with value: 0.933300292802968 and parameters: {'alpha': 996.0218408314649}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,334] Trial 134 finished with value: 0.9330851488571472 and parameters: {'alpha': 392.35516120671315}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,403] Trial 135 finished with value: 0.933175152215949 and parameters: {'alpha': 586.3311830465623}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,496] Trial 136 finished with value: 0.9330335157069505 and parameters: {'alpha': 292.8807380754132}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,578] Trial 137 finished with value: 0.9331679820230887 and parameters: {'alpha': 572.5300714394307}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,666] Trial 138 finished with value: 0.9332963927424999 and parameters: {'alpha': 977.0033629740134}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,748] Trial 139 finished with value: 0.9330587774859822 and parameters: {'alpha': 333.7271073809402}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,834] Trial 140 finished with value: 0.9331266696061303 and parameters: {'alpha': 478.03818868146686}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,918] Trial 141 finished with value: 0.9332973226946116 and parameters: {'alpha': 982.436837161443}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:54,997] Trial 142 finished with value: 0.9332065946557228 and parameters: {'alpha': 664.1637713336627}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,098] Trial 143 finished with value: 0.9332217170695376 and parameters: {'alpha': 713.4189688204679}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,184] Trial 144 finished with value: 0.9331236390537668 and parameters: {'alpha': 473.56281646885753}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,257] Trial 145 finished with value: 0.9332929422140858 and parameters: {'alpha': 953.6950937320267}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,334] Trial 146 finished with value: 0.933018364241132 and parameters: {'alpha': 262.34356644250596}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,416] Trial 147 finished with value: 0.9332034435393445 and parameters: {'alpha': 655.6250175217284}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,498] Trial 148 finished with value: 0.9330762090480743 and parameters: {'alpha': 374.39303218031785}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,582] Trial 149 finished with value: 0.9332987328147807 and parameters: {'alpha': 991.427569896831}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,667] Trial 150 finished with value: 0.9329815507807138 and parameters: {'alpha': 196.66096019617183}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,760] Trial 151 finished with value: 0.9332210866014617 and parameters: {'alpha': 707.1215360790417}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,847] Trial 152 finished with value: 0.9332965126585142 and parameters: {'alpha': 979.4669527358773}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:55,928] Trial 153 finished with value: 0.9328457942244208 and parameters: {'alpha': 0.08865245801766133}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:56,001] Trial 154 finished with value: 0.9332938728501974 and parameters: {'alpha': 973.6146793668355}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:56,086] Trial 155 finished with value: 0.9331451507123485 and parameters: {'alpha': 521.1970855351251}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:56,182] Trial 156 finished with value: 0.9332972327666007 and parameters: {'alpha': 982.182261697864}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:56,286] Trial 157 finished with value: 0.9330685282311526 and parameters: {'alpha': 359.94668191491127}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:56,390] Trial 158 finished with value: 0.9332004137069808 and parameters: {'alpha': 648.0336040373109}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:56,462] Trial 159 finished with value: 0.9331542419014395 and parameters: {'alpha': 539.7954641881539}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:56,559] Trial 160 finished with value: 0.9330990397468143 and parameters: {'alpha': 428.5018205117812}. Best is trial 114 with value: 0.9333007127070183.\n",
      "[I 2024-07-10 12:55:56,651] Trial 161 finished with value: 0.9333009827430508 and parameters: {'alpha': 998.4375309862937}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:56,730] Trial 162 finished with value: 0.9332923121060102 and parameters: {'alpha': 952.3679760506227}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:56,818] Trial 163 finished with value: 0.9331949528663254 and parameters: {'alpha': 637.2692087229246}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:56,900] Trial 164 finished with value: 0.9332246870338939 and parameters: {'alpha': 719.5496887402222}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:56,980] Trial 165 finished with value: 0.9332989730788096 and parameters: {'alpha': 990.0443963302222}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,067] Trial 166 finished with value: 0.933298853018795 and parameters: {'alpha': 990.2572125766367}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,198] Trial 167 finished with value: 0.9330372055993932 and parameters: {'alpha': 298.06822712207133}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,313] Trial 168 finished with value: 0.933299003102813 and parameters: {'alpha': 990.0090159319317}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,413] Trial 169 finished with value: 0.9331237891737847 and parameters: {'alpha': 473.9994352454305}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,497] Trial 170 finished with value: 0.9332130753405004 and parameters: {'alpha': 674.7707441601093}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,583] Trial 171 finished with value: 0.9332878412654737 and parameters: {'alpha': 925.259012089592}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,667] Trial 172 finished with value: 0.9332173365890118 and parameters: {'alpha': 695.3812521182125}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,749] Trial 173 finished with value: 0.9331066592557288 and parameters: {'alpha': 446.39470006212173}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,831] Trial 174 finished with value: 0.9332159263608425 and parameters: {'alpha': 687.373670117051}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,913] Trial 175 finished with value: 0.9332961825744746 and parameters: {'alpha': 977.684922927002}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:57,997] Trial 176 finished with value: 0.9332974127306223 and parameters: {'alpha': 982.2632248033361}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:58,063] Trial 177 finished with value: 0.9331078895558765 and parameters: {'alpha': 451.00806164719137}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:58,153] Trial 178 finished with value: 0.9330531665253088 and parameters: {'alpha': 323.6285543277066}. Best is trial 161 with value: 0.9333009827430508.\n",
      "[I 2024-07-10 12:55:58,232] Trial 179 finished with value: 0.9333015827551225 and parameters: {'alpha': 998.7788621207164}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:58,315] Trial 180 finished with value: 0.9331652513507609 and parameters: {'alpha': 568.5201483371518}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:58,400] Trial 181 finished with value: 0.9332918018419489 and parameters: {'alpha': 948.4770691966147}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:58,483] Trial 182 finished with value: 0.9331956431664082 and parameters: {'alpha': 639.5726376791407}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:58,585] Trial 183 finished with value: 0.9332947727423054 and parameters: {'alpha': 975.2140200761311}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:58,688] Trial 184 finished with value: 0.9331319496907641 and parameters: {'alpha': 492.2923881031229}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:58,767] Trial 185 finished with value: 0.9328501142609392 and parameters: {'alpha': 4.802585436920019}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:58,865] Trial 186 finished with value: 0.9332112755202845 and parameters: {'alpha': 671.6059394619373}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:58,956] Trial 187 finished with value: 0.9330732684237213 and parameters: {'alpha': 367.7925705818668}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:59,034] Trial 188 finished with value: 0.9332217171415377 and parameters: {'alpha': 713.8626008062807}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:59,112] Trial 189 finished with value: 0.9332991527908311 and parameters: {'alpha': 992.9684338225775}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:59,197] Trial 190 finished with value: 0.9330162943488837 and parameters: {'alpha': 261.0618864402399}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:59,283] Trial 191 finished with value: 0.9332965425745178 and parameters: {'alpha': 979.1482297539147}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:59,363] Trial 192 finished with value: 0.9332168566729543 and parameters: {'alpha': 694.9609512037446}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:59,450] Trial 193 finished with value: 0.933296542754518 and parameters: {'alpha': 979.9931911460845}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:59,530] Trial 194 finished with value: 0.9331351897991529 and parameters: {'alpha': 496.2073213261932}. Best is trial 179 with value: 0.9333015827551225.\n",
      "[I 2024-07-10 12:55:59,630] Trial 195 finished with value: 0.933301792887148 and parameters: {'alpha': 999.5259292271376}. Best is trial 195 with value: 0.933301792887148.\n",
      "[I 2024-07-10 12:55:59,715] Trial 196 finished with value: 0.9328456443204027 and parameters: {'alpha': 0.00010879626309665402}. Best is trial 195 with value: 0.933301792887148.\n",
      "[I 2024-07-10 12:55:59,797] Trial 197 finished with value: 0.9333006828270148 and parameters: {'alpha': 997.2770960817327}. Best is trial 195 with value: 0.933301792887148.\n",
      "[I 2024-07-10 12:55:59,880] Trial 198 finished with value: 0.9331503412649713 and parameters: {'alpha': 533.71672885129}. Best is trial 195 with value: 0.933301792887148.\n",
      "[I 2024-07-10 12:55:59,970] Trial 199 finished with value: 0.9332032934193264 and parameters: {'alpha': 655.1060509673251}. Best is trial 195 with value: 0.933301792887148.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ridge Classifier의 목적 함수\n",
    "def ridge_classifier_objective(trial):\n",
    "\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e3, log=True)\n",
    "    clf = RidgeClassifier(alpha=alpha)\n",
    "    \n",
    "    # 교차 검증을 통한 모델 평가 (AUC 스코어)\n",
    "    # 다중 클래스의 경우, 'ovr' 또는 'ovo' 스키마를 사용\n",
    "    # if len(set(y_train_resampled)) > 2:\n",
    "    #     scoring = 'roc_auc_ovr'\n",
    "    # else:\n",
    "    #     scoring = 'roc_auc'\n",
    "    \n",
    "    scores = cross_val_score(clf, shap_xgb_X_train_resampled, y_train_resampled, cv=6, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "ridge_classifier_study = optuna.create_study(direction='maximize')\n",
    "ridge_classifier_study.optimize(ridge_classifier_objective, n_trials=200)\n",
    "ridge_classifier_best_params = ridge_classifier_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최적의 하이퍼파라미터로 최종 모델 학습 및 평가\n",
    "# model_ridge_classifier = RidgeClassifier(**ridge_classifier_best_params)\n",
    "# model_ridge_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # 검증 데이터로 예측\n",
    "# y_pred = model_ridge_classifier.predict(X_val)\n",
    "\n",
    "# # 정확도 계산\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8802377115229653\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터로 최종 모델 학습 및 평가\n",
    "model_ridge_classifier = RidgeClassifier(**ridge_classifier_best_params)\n",
    "model_ridge_classifier.fit(shap_xgb_X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 검증 데이터로 예측\n",
    "y_pred = model_ridge_classifier.predict(shap_xgb_X_val)\n",
    "y_pred_proba = model_ridge_classifier.decision_function(shap_xgb_X_val)\n",
    "\n",
    "# 다중 클래스의 경우 ROC AUC 스코어 계산\n",
    "if len(set(y_val)) > 2:\n",
    "    y_val_bin = label_binarize(y_val, classes=list(set(y_val)))\n",
    "    auc_score = roc_auc_score(y_val_bin, y_pred_proba, multi_class='ovr')\n",
    "else:\n",
    "    auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "print(\"AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis=LogisticRegression(l1_ratio= 0.789370019111903, C= 0.07701480047825814, max_iter= 1000)\n",
    "model_logis.fit(X_train_resampled,y_train_resampled)\n",
    "y_pred = model_logis.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomforest feature selection  큰 효과가 없는 듯 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier()\n",
    "# model.fit(train_resampled, y_train_resampled)\n",
    "# y_pred = model.predict(test)\n",
    "\n",
    "# rn_features = []\n",
    "# importances = model.feature_importances_\n",
    "# feature_names = train.columns\n",
    "\n",
    "# # 피처 중요도를 기준으로 정렬하여 상위 피처 선택\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # 중요도가 0.01 이상인 피처만 선택\n",
    "# # top_number = 40\n",
    "# top_num_indices = [idx for idx in indices if importances[idx] >= 0.005] #[:top_number]\n",
    "# top_features = feature_names[top_num_indices]\n",
    "\n",
    "# for i, feature in enumerate(top_features):\n",
    "#     print(f\"{i+1}. {feature} (중요도: {importances[top_num_indices[i]]})\")\n",
    "#     rn_features.append(feature)\n",
    "\n",
    "# rn_train_resampled = train_resampled[rn_features]\n",
    "# rn_test = test[rn_features]\n",
    "\n",
    "# model_logis=LogisticRegression(**logreg_best_params)\n",
    "# model_logis.fit(rn_train_resampled,y_train_resampled)\n",
    "# y_pred = model_logis.predict(rn_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관계수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "corr_number = 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > corr_number)]\n",
    "to_drop\n",
    "# # 특징 제거\n",
    "corr_X_train_resampled = X_train_resampled.drop(columns=to_drop)  \n",
    "corr_X_val = X_val.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_objective(trial):\n",
    "    \n",
    "    r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "     \n",
    "    clf =  LogisticRegression(max_iter=5000, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "    scores = cross_val_score(clf, corr_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "logreg_study = optuna.create_study(direction='maximize')\n",
    "logreg_study.optimize(logreg_objective, n_trials=5)\n",
    "\n",
    "logreg_best_params = logreg_study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis=LogisticRegression(**logreg_best_params)\n",
    "model_logis.fit(corr_X_train_resampled,y_train_resampled)\n",
    "y_pred = model_logis.predict(corr_X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 규제(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 값 후보군 설정\n",
    "alpha_values = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 100]\n",
    "param_grid = {'alpha': alpha_values}\n",
    "\n",
    "# Lasso 모델과 GridSearchCV 설정\n",
    "lasso = Lasso()\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# 최적의 alpha 값 찾기\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=best_alpha)  # 위에서 나온 alpha 값으로 조정한 거임\n",
    "lasso.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 가중치가 0이 아닌 특징 선택\n",
    "selected_features = X_train_resampled.columns[lasso.coef_ != 0]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_X_train_resampled = X_train_resampled[selected_features]\n",
    "L1_X_val = X_val[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_objective(trial):\n",
    "    \n",
    "    r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "     \n",
    "    clf =  LogisticRegression(max_iter=5000, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "    scores = cross_val_score(clf, L1_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "logreg_study = optuna.create_study(direction='maximize')\n",
    "logreg_study.optimize(logreg_objective, n_trials=5)\n",
    "\n",
    "logreg_best_params = logreg_study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2013~2023  \n",
    "### 많긴 하지만 정확도 떨어질 것으로 예상됨\n",
    "\n",
    "# 2020~2023\n",
    "### 데이터 수가 급격히 줄어듬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
