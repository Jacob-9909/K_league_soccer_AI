{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib import font_manager, rc\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "# from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, PowerTransformer, OrdinalEncoder,\n",
    "    OneHotEncoder, FunctionTransformer, PolynomialFeatures, LabelEncoder, MinMaxScaler\n",
    ")\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, RFE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, LinearRegression, Ridge, Lasso,\n",
    "    SGDRegressor, ElasticNet\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, cross_validate,\n",
    "    GridSearchCV, KFold, cross_val_predict\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, mean_squared_error, make_scorer, accuracy_score, log_loss\n",
    ")\n",
    "from sklearn import set_config, datasets\n",
    "from catboost import (\n",
    "    CatBoostRegressor, CatBoostClassifier,\n",
    ")\n",
    "# import category_encoders as ce\n",
    "# from sklearn.pipeline import (\n",
    "#     Pipeline, FeatureUnion, make_pipeline\n",
    "# )\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, StackingClassifier, StackingRegressor,\n",
    "    GradientBoostingRegressor, VotingClassifier, VotingRegressor,\n",
    "    HistGradientBoostingRegressor, GradientBoostingClassifier,\n",
    "    BaggingClassifier, AdaBoostClassifier, RandomForestRegressor,ExtraTreesRegressor\n",
    ")\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import math\n",
    "import optuna\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('matches_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_encoding(train):\n",
    "    train['home_win'] = train['home_team_result'].apply(lambda x: 1 if x=='승' else 0) # home_win 열 추가, 승리인 경우 1, 아닌 경우 0\n",
    "    dic = {}\n",
    "    # 각 홈팀별 이긴 경기 수를 딕셔너리에 저장\n",
    "    for team in train['home_team_name'].unique():\n",
    "        value = train[train['home_team_name'] == team]['home_win'].sum() \n",
    "        #home_team_name  열에서 고유한 팀 이름을 가져와 각 팀이 홈에서 이긴 경기 수 계산, 이 값을 dic에 저장\n",
    "        dic[team] = value\n",
    "\n",
    "    label_dic={}\n",
    "    # 승리 횧수를 기준으로 오름차순 정렬, 각 팀에 대해 라벨 부여, 승리 횟수가 적은 팀부터 0,1,2 의 라벨을 부여\n",
    "    for idx, (team, _) in enumerate(sorted(dic.items(), key= lambda x: x[1])):\n",
    "        label_dic[team] = idx\n",
    "    \n",
    "    return label_dic\n",
    "\n",
    "\n",
    "''' 홈팀 득점 이동평균 계산 함수 '''\n",
    "\n",
    "def homeGoal_day_mean(train, test, day):\n",
    "    train[f'home_Goal_{day}_mean'] = -1  # 초기값 -1로 설정\n",
    "    test[f'home_Goal_{day}_mean'] = -1\n",
    "    \n",
    "    teams = train['home_team_name'].unique()\n",
    "    for team in tqdm(teams): # train에서 고유 팀 이름을 가져오고 이를 시각적으로 표시해줌 : tqdm\n",
    "        team_df = train[train['home_team_name'] == team]\n",
    "        # 롤링 윈도우 크기 설정\n",
    "        ch_day = len(team_df) if len(team_df) < day else day # 팀의 경기 수가 주어진 day 보다 적으면, 경기 수 만큼의 윈도우 크기 사용\n",
    "        idx = team_df['home_team_goal_count'].rolling(ch_day).mean().index.values # 롤링 윈도우 평균 계산\n",
    "        val = team_df['home_team_goal_count'].rolling(ch_day).mean().values\n",
    "        train[f'home_Goal_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['home_team_name'] == team].index\n",
    "        test[f'home_Goal_{day}_mean'].loc[test_idx] = val[-1]\n",
    "    # 결측값 처리\n",
    "    train[f'home_Goal_{day}_mean'] = train[f'home_Goal_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "''' 원정팀 득점 이동평균 계산 함수 '''\n",
    "\n",
    "def awayGoal_day_mean(train, test, day):\n",
    "    # 초기값 설정\n",
    "    train[f'away_Goal_{day}_mean'] = -1\n",
    "    test[f'away_Goal_{day}_mean'] = -1\n",
    "    \n",
    "    teams = train['away_team_name'].unique()\n",
    "    for team in tqdm(teams):\n",
    "        team_df = train[train['away_team_name'] == team]\n",
    "        # 롤링 윈도우 크기 설정\n",
    "        ch_day = len(team_df) if len(team_df) < day else day\n",
    "        idx = team_df['away_team_goal_count'].rolling(ch_day).mean().index.values\n",
    "        val = team_df['away_team_goal_count'].rolling(ch_day).mean().values\n",
    "        train[f'away_Goal_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['away_team_name'] == team].index\n",
    "        test[f'away_Goal_{day}_mean'].loc[test_idx] = val[-1]\n",
    "    # 결측값 처리\n",
    "    train[f'away_Goal_{day}_mean'] = train[f'away_Goal_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''홈팀 승리율 평균 계산 함수'''\n",
    "\n",
    "def homeWin_day_mean(train, test, day):\n",
    "    train[f'home_winRate_{day}_mean'] = -1\n",
    "    test[f'home_winRate_{day}_mean'] = -1\n",
    "    train['win'] = train['home_team_result'].apply(lambda x: 1 if x == '승' else 0)\n",
    "\n",
    "    teams = train['home_team_name'].unique()\n",
    "    for team in tqdm(teams):\n",
    "        team_df = train[train['home_team_name'] == team]\n",
    "        ch_day = len(team_df) if len(team_df) < day else day\n",
    "        idx = team_df['win'].rolling(ch_day).mean().index.values\n",
    "        val = team_df['win'].rolling(ch_day).mean().values\n",
    "        train[f'home_winRate_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['home_team_name'] == team].index\n",
    "        test[f'home_winRate_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "    train.drop(columns=['win'], inplace=True)\n",
    "\n",
    "    train[f'home_winRate_{day}_mean'] = train[f'home_winRate_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''원정팀 승리율 평균 계산 함수'''\n",
    "\n",
    "def awayWin_day_mean(train, test, day):\n",
    "\n",
    "    train[f'away_winRate_{day}_mean'] = -1\n",
    "    test[f'away_winRate_{day}_mean'] = -1\n",
    "    train['win'] = train['home_team_result'].apply(lambda x: 1 if x == '패' else 0)\n",
    "    \n",
    "    teams = train['away_team_name'].unique()\n",
    "    for team in tqdm(teams):\n",
    "        team_df = train[train['away_team_name'] == team]\n",
    "\n",
    "        ch_day = len(team_df) if len(team_df) < day else day\n",
    "        idx = team_df['win'].rolling(ch_day).mean().index.values\n",
    "        val = team_df['win'].rolling(ch_day).mean().values\n",
    "        train[f'away_winRate_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['away_team_name'] == team].index\n",
    "        test[f'away_winRate_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "    train.drop(columns=['win'], inplace=True)\n",
    "\n",
    "    train[f'away_winRate_{day}_mean'] = train[f'away_winRate_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''홈팀 평균 계산 함수'''\n",
    "\n",
    "def home_day_mean(train, test, columns, day):\n",
    "    for column in tqdm(columns):\n",
    "        teams = train['home_team_name'].values\n",
    "        train[f'home_{column}_{day}_mean'] = -1\n",
    "        test[f'home_{column}_{day}_mean'] = -1\n",
    "\n",
    "        for team in tqdm(teams):\n",
    "            team_df = train[train['home_team_name'] == team]\n",
    "            idx = team_df[column].rolling(day).mean().index.values\n",
    "            val = team_df[column].rolling(day).mean().values\n",
    "            train[f'home_{column}_{day}_mean'].loc[idx] = val\n",
    "            test_idx = test[test['home_team_name'] == team].index\n",
    "            test[f'home_{column}_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "        train[f'home_{column}_{day}_mean'] = train[f'home_{column}_{day}_mean'].fillna(0)\n",
    "        test[f'home_{column}_{day}_mean'] = test[f'home_{column}_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''원정팀 평균 계산 함수'''\n",
    "\n",
    "def away_day_mean(train, test, columns, day):\n",
    "    for column in tqdm(columns):\n",
    "        teams = train['away_team_name'].values\n",
    "        train[f'away_{column}_{day}_mean'] = -1\n",
    "        test[f'away_{column}_{day}_mean'] = -1\n",
    "\n",
    "        for team in tqdm(teams):\n",
    "            team_df = train[train['away_team_name'] == team]\n",
    "            idx = team_df[column].rolling(day).mean().index.values\n",
    "            val = team_df[column].rolling(day).mean().values\n",
    "            train[f'away_{column}_{day}_mean'].loc[idx] = val\n",
    "            test_idx = test[test['away_team_name'] == team].index\n",
    "            test[f'away_{column}_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "        train[f'away_{column}_{day}_mean'] = train[f'away_{column}_{day}_mean'].fillna(0)\n",
    "        test[f'away_{column}_{day}_mean'] = test[f'away_{column}_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''전처리 함수'''\n",
    "\n",
    "def preprocessing(train, test):\n",
    "    # 년과 월일로 나누기\n",
    "    train['date_GMT'] = train['date_GMT'].dt.strftime('%Y%m%d')\n",
    "    test['date_GMT'] = test['date_GMT'].dt.strftime('%Y%m%d')\n",
    "    \n",
    "    train['year'] = train['date_GMT'].apply(lambda x : int(x[0:4]))\n",
    "    train['date'] = train['date_GMT'].apply(lambda x : int(x[4:10]))\n",
    "\n",
    "    test['year'] = test['date_GMT'].apply(lambda x : int(x[0:4]))\n",
    "    test['date'] = test['date_GMT'].apply(lambda x : int(x[4:10]))\n",
    "\n",
    "    # train.drop(columns=['date_GMT'], inplace=True)\n",
    "    # test.drop(columns=['date_GMT'], inplace=True)\n",
    "\n",
    "    # # 팀 인코딩 적용   # 위에서 적용 했음\n",
    "    # label_dic = dic\n",
    "    # train['home_team_name'] = train['home_team_name'].apply(lambda x: label_dic[x])\n",
    "    # train['away_team_name'] = train['away_team_name'].apply(lambda x: label_dic[x])\n",
    "    # test['home_team_name'] = test['home_team_name'].apply(lambda x: label_dic[x])\n",
    "    # test['away_team_name'] = test['away_team_name'].apply(lambda x: label_dic[x])\n",
    "\n",
    "    # # 5일간 홈팀 승리 비율 계산\n",
    "    # homeWin_day_mean(train, test, 5)\n",
    "    # # 5일간 원정팀 승리 비율 계산\n",
    "    # awayWin_day_mean(train, test, 5)\n",
    "\n",
    "    # 5일간 홈팀 평균 득점 계산\n",
    "    homeGoal_day_mean(train, test, 5)\n",
    "\n",
    "    # 5일간 원정팀 평균 득점 계산\n",
    "    awayGoal_day_mean(train, test, 5)\n",
    "\n",
    "    # 불필요한 컬럼 제거\n",
    "    # train = train.drop(columns=['home_win', 'index','home_team_goal_count','away_team_goal_count','home_team_result','game_points'])\n",
    "    train = train.drop(columns=['index','home_team_goal_count','away_team_goal_count','game_points'])\n",
    "    test = test.drop(columns=['index','home_team_goal_count','away_team_goal_count','home_team_result','game_points'])\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = df['home_team_result']\n",
    "\n",
    "# split_index = 1796 # 2021년도까지의 index\n",
    "# train = X.iloc[:split_index]\n",
    "# test = X.iloc[split_index:]\n",
    "# y_train = y.iloc[:split_index]\n",
    "# y_test = y.iloc[split_index:]\n",
    "\n",
    "# team_name 인코딩\n",
    "cat = ['home_team_name','away_team_name']\n",
    "le = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, dtype=int)\n",
    "X[cat] = le.fit_transform(X[cat])\n",
    "\n",
    "# 승무패 인코딩\n",
    "lec = LabelEncoder()\n",
    "lec.fit(X['home_team_result'])\n",
    "y = lec.transform(y)\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42) ## 이 방법에 의문을 품는 바이요!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 462.70it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 543.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1984, 29) (496, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# hometeam_list = list(X_train['home_team_name'].unique())\n",
    "# dic = team_encoding(X_train)\n",
    "X_train, X_val= preprocessing(X_train, X_val)\n",
    "X_val_idx = X_val.index.values\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홈팀과 원정팀의 공격 효율성을 계산한 피쳐 생성\n",
    "X_train['home_attack_efficiency'] = X_train['home_Goal_5_mean'] * X_train['home_team_shots_on_target']\n",
    "X_train['away_attack_efficiency'] = X_train['away_Goal_5_mean'] * X_train['away_team_shots_on_target']\n",
    "# 홈팀과 원정팀의 공격 효율성 차이를 나타내는 피쳐 생성\n",
    "X_train['attack_efficiency_difference'] = X_train['home_attack_efficiency'] - X_train['away_attack_efficiency']\n",
    "\n",
    "# 최근 5경기 평균 득점의 표준 편차를 나타내는 피쳐 생성\n",
    "X_train['home_Goal_5_std'] = X_train['home_Goal_5_mean'].rolling(window=5).std()\n",
    "X_train['away_Goal_5_std'] = X_train['away_Goal_5_mean'].rolling(window=5).std()\n",
    "\n",
    "# 결측값을 0으로 대체\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "# 테스트 데이터에도 동일한 피쳐 생성\n",
    "X_val['home_attack_efficiency'] = X_val['home_Goal_5_mean'] * X_val['home_team_shots_on_target']\n",
    "X_val['away_attack_efficiency'] = X_val['away_Goal_5_mean'] * X_val['away_team_shots_on_target']\n",
    "X_val['attack_efficiency_difference'] = X_val['home_attack_efficiency'] - X_val['away_attack_efficiency']\n",
    "X_val['home_Goal_5_std'] = X_val['home_Goal_5_mean'].rolling(window=5).std()\n",
    "X_val['away_Goal_5_std'] = X_val['away_Goal_5_mean'].rolling(window=5).std()\n",
    "X_val = X_val.fillna(0)\n",
    "\n",
    "# 학습 데이터에서 목표 변수 'home_team_result' 컬럼 제거\n",
    "X_train.drop(columns = ['home_team_result'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sweetviz as sv\n",
    "\n",
    "# report = sv.analyze(train)\n",
    "# report.show_html(\"new_features.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['home_team_name','away_team_name']\n",
    "\n",
    "num_features = list(set(X_train.columns) - set(cat))\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_val[num_features] = scaler.transform(X_val[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0: 5000, 2: 5000, 1: 5000})\n",
      "Original training set shape: (1984, 33)\n",
      "Resampled training set shape: (15000, 33)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# SMOTE 객체 생성 (각 클래스의 샘플 수를 1000개로 설정)\n",
    "smote = SMOTE(sampling_strategy={0: 5000, 1: 5000, 2: 5000}, random_state=42)\n",
    "\n",
    "# SMOTE-Tomek 객체 생성\n",
    "smote_tomek = SMOTETomek(smote=smote, random_state=42)\n",
    "\n",
    "# 오버샘플링 및 언더샘플링 적용\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# 각 클래스 비율 확인\n",
    "print(f\"Resampled class distribution: {Counter(y_train_resampled)}\")\n",
    "\n",
    "print(f\"Original training set shape: {X_train.shape}\")\n",
    "print(f\"Resampled training set shape: {X_train_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.6209677419354839\n",
      "Filtered SHAP Importances:\n",
      "                        column_name  shap_importance\n",
      "17  home_team_goal_count_half_time         0.912415\n",
      "23                  5_games_result         0.879900\n",
      "18  away_team_goal_count_half_time         0.760302\n",
      "30    attack_efficiency_difference         0.701513\n",
      "7        home_team_shots_on_target         0.596670\n",
      "5                  home_team_shots         0.230766\n",
      "11            home_team_possession         0.210078\n",
      "26                home_Goal_5_mean         0.154896\n",
      "22             away_team_red_cards         0.151089\n",
      "2                   away_team_name         0.147995\n",
      "3           home_team_corner_count         0.145870\n",
      "4           away_team_corner_count         0.137429\n",
      "32                 away_Goal_5_std         0.137076\n",
      "8        away_team_shots_on_target         0.135907\n",
      "10                 away_team_fouls         0.117758\n",
      "29          away_attack_efficiency         0.117020\n",
      "27                away_Goal_5_mean         0.116118\n",
      "16               away_team_offside         0.114090\n",
      "9                  home_team_fouls         0.108995\n",
      "28          home_attack_efficiency         0.105096\n",
      "15               home_team_offside         0.103162\n",
      "19          home_team_yellow_cards         0.102584\n",
      "25                            date         0.097527\n",
      "21          away_team_yellow_cards         0.097086\n",
      "1                   home_team_name         0.090687\n",
      "20             home_team_red_cards         0.090318\n",
      "12            away_team_possession         0.086340\n",
      "6                  away_team_shots         0.077712\n",
      "0                         date_GMT         0.076865\n",
      "31                 home_Goal_5_std         0.071819\n",
      "13             home_team_free_kick         0.063962\n",
      "14             away_team_free_kick         0.057498\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import shap\n",
    "SHAP_THRESHOLD = 0.05\n",
    "\n",
    "# feature_names dimension 조정\n",
    "X_train_col = X_train.columns\n",
    "feature_names = X_train_col.to_numpy()\n",
    "\n",
    "# 모델 학습\n",
    "model = xgb.XGBClassifier().fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 모델 예측 및 평가\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# SHAP 값 계산\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "# SHAP 값 요약\n",
    "if isinstance(shap_values, list):  # shap_values가 리스트일 경우 (XGBoost >= 1.0.0)\n",
    "    shap_values = shap_values[1]\n",
    "\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame({'column_name': feature_names, 'shap_importance': shap_sum})\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "\n",
    "# 중요도 임계값 적용 (선택 사항)\n",
    "importance_df_filtered = importance_df[importance_df['shap_importance'] > SHAP_THRESHOLD]\n",
    "print(\"Filtered SHAP Importances:\\n\", importance_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된(SHAP_THRESHOLD) Shap feature 중요도 이상인 것만 선택\n",
    "features_selected = importance_df.query('shap_importance > @SHAP_THRESHOLD').column_name.tolist()\n",
    "shap_xgb_X_train_resampled = X_train_resampled[features_selected]\n",
    "shap_xgb_X_val = X_val[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LightGBM 모델 학습\n",
    "# model = lgb.LGBMClassifier().fit(X_train_resampled, y_train_resampled)\n",
    "# SHAP_THRESHOLD = 0.1\n",
    "\n",
    "# # 모델 예측 및 평가\n",
    "# y_pred = model.predict(X_val)\n",
    "# print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# # SHAP 값 계산\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "# shap_sum = np.abs(shap_values).mean(axis=1)[1,:]\n",
    "# importance_df = pd.DataFrame([X_val.columns.tolist(), shap_sum.tolist()]).T\n",
    "# importance_df.columns = ['column_name', 'shap_importance']\n",
    "# importance_df = importance_df.sort_values('shap_importance', ascending=False);\n",
    "# # importance_df\n",
    "\n",
    "# # # SHAP 값 데이터프레임 생성 (각 피쳐별 SHAP 값)\n",
    "# # shap_values_df = pd.DataFrame(shap_values[1], columns=test.columns)\n",
    "# # shap_values_df\n",
    "\n",
    "# # SHAP 값의 평균 절대값 계산\n",
    "# shap_abs_mean = pd.DataFrame(shap_values[1], columns=X_val.columns).abs().mean().sort_values(ascending=False)\n",
    "\n",
    "# # SHAP 값 평균 절대값 시각화\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# shap_abs_mean.plot(kind='barh')\n",
    "# plt.title(\"Mean Absolute SHAP Values for Features\")\n",
    "# plt.xlabel(\"Mean Absolute SHAP Value\")\n",
    "# plt.ylabel(\"Features\")\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 지정된(SHAP_THRESHOLD) Shap feature 중요도 이상인 것만 선택\n",
    "# features_selected = importance_df.query('shap_importance > @SHAP_THRESHOLD').column_name.tolist()\n",
    "# shap_lgbm_X_train_resampled = X_train_resampled[features_selected]\n",
    "# shap_lgbm_X_val = X_val[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model Oputna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgboostclassifier\n",
    "# import optuna\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# def xgb_objective(trial):\n",
    "#     # 하이퍼파라미터 범위 설정\n",
    "#     max_depth = trial.suggest_int('max_depth', 3, 7)  # max_depth의 범위를 줄임\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 50, 200)  # n_estimators의 범위를 줄임\n",
    "#     subsample = trial.suggest_float('subsample', 0.5, 0.9)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 0.9)\n",
    "#     min_child_weight = trial.suggest_int('min_child_weight', 4, 10)  # 추가\n",
    "#     gamma = trial.suggest_float('gamma', 0, 5)  # 추가\n",
    "    \n",
    "#     # XGBClassifier 모델 정의\n",
    "#     clf = XGBClassifier(\n",
    "#         max_depth=max_depth,\n",
    "#         learning_rate=learning_rate,\n",
    "#         n_estimators=n_estimators,\n",
    "#         subsample=subsample,\n",
    "#         colsample_bytree=colsample_bytree,\n",
    "#         min_child_weight=min_child_weight,  # 추가\n",
    "#         gamma=gamma,  # 추가\n",
    "#         use_label_encoder=False,\n",
    "#         eval_metric='logloss'\n",
    "#     )\n",
    "    \n",
    "#     # 교차 검증 점수 계산\n",
    "#     scores = cross_val_score(clf, shap_xgb_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "#     return scores.mean()\n",
    "\n",
    "# # Optuna 스터디 생성 및 최적화\n",
    "# xgb_study = optuna.create_study(direction='maximize')\n",
    "# xgb_study.optimize(xgb_objective, n_trials=50)  # 최적화 반복 횟수는 필요에 따라 조절\n",
    "\n",
    "# # 최적 하이퍼파라미터 출력\n",
    "# xgb_best_params = xgb_study.best_params\n",
    "# print(' ')\n",
    "# print(xgb_study.best_value)\n",
    "# print(xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_logis=xgb.XGBClassifier(**xgb_best_params)\n",
    "# # model_logis=xgb.XGBClassifier(max_depth= 4, learning_rate= 0.00020353095689003422, n_estimators= 229, subsample= 0.5217582675029752, colsample_bytree= 0.5421399627551824)\n",
    "# model_logis.fit(shap_xgb_X_train_resampled, y_train_resampled)\n",
    "# y_pred = model_logis.predict(shap_xgb_X_val)\n",
    "\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy=\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-03 16:02:17,328] A new study created in memory with name: no-name-0f8920fe-7879-4242-a064-b029df5cf833\n",
      "[I 2024-07-03 16:02:19,981] Trial 0 finished with value: 0.6853999999999999 and parameters: {'l1_ratio': 0.789370019111903, 'C': 0.07701480047825814, 'max_iter': 1000}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:02:24,776] Trial 1 finished with value: 0.6843333333333333 and parameters: {'l1_ratio': 0.12096022217318084, 'C': 0.08431569692608468, 'max_iter': 500}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:02:24,992] Trial 2 finished with value: 0.3333333333333333 and parameters: {'l1_ratio': 0.852317084609612, 'C': 0.00010551569896811869, 'max_iter': 1000}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:02:26,319] Trial 3 finished with value: 0.6654 and parameters: {'l1_ratio': 0.8140638333470256, 'C': 0.0033985665753876564, 'max_iter': 1000}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:02:47,837] Trial 4 finished with value: 0.6849333333333333 and parameters: {'l1_ratio': 0.7074700512447861, 'C': 18.98158768271748, 'max_iter': 500}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:03:16,021] Trial 5 finished with value: 0.6851333333333334 and parameters: {'l1_ratio': 0.12523133453352894, 'C': 1.1140867084792065, 'max_iter': 1000}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:03:17,776] Trial 6 finished with value: 0.6819333333333335 and parameters: {'l1_ratio': 0.48940601000875883, 'C': 0.010244704731074547, 'max_iter': 1000}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:03:40,312] Trial 7 finished with value: 0.6849999999999999 and parameters: {'l1_ratio': 0.8617162232364363, 'C': 3.3623569549497923, 'max_iter': 500}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:04:01,911] Trial 8 finished with value: 0.6849333333333334 and parameters: {'l1_ratio': 0.6166460706834531, 'C': 0.42689520370723916, 'max_iter': 500}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:04:04,497] Trial 9 finished with value: 0.6798666666666666 and parameters: {'l1_ratio': 0.8413435936926035, 'C': 0.013814848626192106, 'max_iter': 500}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:04:05,338] Trial 10 finished with value: 0.6282666666666666 and parameters: {'l1_ratio': 0.4369627942115384, 'C': 0.00033100212860693717, 'max_iter': 1500}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:04:30,690] Trial 11 finished with value: 0.6850666666666667 and parameters: {'l1_ratio': 0.10565775311767034, 'C': 0.8771144548198261, 'max_iter': 1500}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:05:14,137] Trial 12 finished with value: 0.6849333333333333 and parameters: {'l1_ratio': 0.259299476141553, 'C': 40.07288893876471, 'max_iter': 1000}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:05:23,048] Trial 13 finished with value: 0.6851333333333334 and parameters: {'l1_ratio': 0.33219222469564735, 'C': 0.15643949236830257, 'max_iter': 1500}. Best is trial 0 with value: 0.6853999999999999.\n",
      "[I 2024-07-03 16:06:06,419] Trial 14 finished with value: 0.6849999999999999 and parameters: {'l1_ratio': 0.6511354559594529, 'C': 1.7133892907922168, 'max_iter': 1000}. Best is trial 0 with value: 0.6853999999999999.\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "def logreg_objective(trial):\n",
    "\n",
    "    r = trial.suggest_float('l1_ratio', 0.1, 0.9, log=False)  # 범위를 0.1에서 0.9로 좁힘\n",
    "    c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "    max_iter = trial.suggest_int('max_iter', 500, 1500, step=500)  # max_iter 튜닝 추가\n",
    "    \n",
    "    clf =  LogisticRegression(max_iter=max_iter, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "    scores = cross_val_score(clf, shap_xgb_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "logreg_study = optuna.create_study(direction='maximize')\n",
    "logreg_study.optimize(logreg_objective, n_trials=15)\n",
    "\n",
    "logreg_best_params = logreg_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 0.789370019111903, 'C': 0.07701480047825814, 'max_iter': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(logreg_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['home_team_goal_count_half_time', '5_games_result',\n",
      "       'away_team_goal_count_half_time', 'attack_efficiency_difference',\n",
      "       'home_team_shots_on_target', 'home_team_shots', 'home_team_possession',\n",
      "       'home_Goal_5_mean', 'away_team_red_cards', 'away_team_name',\n",
      "       'home_team_corner_count', 'away_team_corner_count', 'away_Goal_5_std',\n",
      "       'away_team_shots_on_target', 'away_team_fouls',\n",
      "       'away_attack_efficiency', 'away_Goal_5_mean', 'away_team_offside',\n",
      "       'home_team_fouls', 'home_attack_efficiency', 'home_team_offside',\n",
      "       'home_team_yellow_cards', 'date', 'away_team_yellow_cards',\n",
      "       'home_team_name', 'home_team_red_cards', 'away_team_possession',\n",
      "       'away_team_shots', 'date_GMT', 'home_Goal_5_std', 'home_team_free_kick',\n",
      "       'away_team_free_kick'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(shap_xgb_X_train_resampled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6794354838709677\n"
     ]
    }
   ],
   "source": [
    "model_logis=LogisticRegression(**logreg_best_params)\n",
    "model_logis.fit(shap_xgb_X_train_resampled,y_train_resampled)\n",
    "y_pred = model_logis.predict(shap_xgb_X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomforest feature selection  큰 효과가 없는 듯 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier()\n",
    "# model.fit(train_resampled, y_train_resampled)\n",
    "# y_pred = model.predict(test)\n",
    "\n",
    "# rn_features = []\n",
    "# importances = model.feature_importances_\n",
    "# feature_names = train.columns\n",
    "\n",
    "# # 피처 중요도를 기준으로 정렬하여 상위 피처 선택\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # 중요도가 0.01 이상인 피처만 선택\n",
    "# # top_number = 40\n",
    "# top_num_indices = [idx for idx in indices if importances[idx] >= 0.005] #[:top_number]\n",
    "# top_features = feature_names[top_num_indices]\n",
    "\n",
    "# for i, feature in enumerate(top_features):\n",
    "#     print(f\"{i+1}. {feature} (중요도: {importances[top_num_indices[i]]})\")\n",
    "#     rn_features.append(feature)\n",
    "\n",
    "# rn_train_resampled = train_resampled[rn_features]\n",
    "# rn_test = test[rn_features]\n",
    "\n",
    "# model_logis=LogisticRegression(**logreg_best_params)\n",
    "# model_logis.fit(rn_train_resampled,y_train_resampled)\n",
    "# y_pred = model_logis.predict(rn_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관계수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "corr_number = 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > corr_number)]\n",
    "to_drop\n",
    "# # 특징 제거\n",
    "corr_X_train_resampled = X_train_resampled.drop(columns=to_drop)  \n",
    "corr_X_val = X_val.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_objective(trial):\n",
    "    \n",
    "    r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "     \n",
    "    clf =  LogisticRegression(max_iter=5000, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "    scores = cross_val_score(clf, corr_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "logreg_study = optuna.create_study(direction='maximize')\n",
    "logreg_study.optimize(logreg_objective, n_trials=5)\n",
    "\n",
    "logreg_best_params = logreg_study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis=LogisticRegression(**logreg_best_params)\n",
    "model_logis.fit(corr_X_train_resampled,y_train_resampled)\n",
    "y_pred = model_logis.predict(corr_X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 규제(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 값 후보군 설정\n",
    "alpha_values = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 100]\n",
    "param_grid = {'alpha': alpha_values}\n",
    "\n",
    "# Lasso 모델과 GridSearchCV 설정\n",
    "lasso = Lasso()\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# 최적의 alpha 값 찾기\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=best_alpha)  # 위에서 나온 alpha 값으로 조정한 거임\n",
    "lasso.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 가중치가 0이 아닌 특징 선택\n",
    "selected_features = X_train_resampled.columns[lasso.coef_ != 0]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_X_train_resampled = X_train_resampled[selected_features]\n",
    "L1_X_val = X_val[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_objective(trial):\n",
    "    \n",
    "    r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "     \n",
    "    clf =  LogisticRegression(max_iter=5000, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "    scores = cross_val_score(clf, L1_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "logreg_study = optuna.create_study(direction='maximize')\n",
    "logreg_study.optimize(logreg_objective, n_trials=5)\n",
    "\n",
    "logreg_best_params = logreg_study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis=LogisticRegression(**logreg_best_params)\n",
    "model_logis.fit(L1_X_train_resampled,y_train_resampled)\n",
    "\n",
    "y_pred = model_logis.predict(L1_X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lgb.LGBMClassifier(n_estimators=100, random_state=42)\n",
    "# model.fit(train, y_train) \n",
    "# y_pred = model.predict(test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2013~2023  \n",
    "### 많긴 하지만 정확도 떨어질 것으로 예상됨\n",
    "\n",
    "# 2020~2023\n",
    "### 데이터 수가 급격히 줄어듬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
