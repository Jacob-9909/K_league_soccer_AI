{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wooyong\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib import font_manager, rc\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "# from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, PowerTransformer, OrdinalEncoder,\n",
    "    OneHotEncoder, FunctionTransformer, PolynomialFeatures, LabelEncoder, MinMaxScaler\n",
    ")\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, RFE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, LinearRegression, Ridge, Lasso,\n",
    "    SGDRegressor, ElasticNet\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, cross_validate,\n",
    "    GridSearchCV, KFold, cross_val_predict\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, mean_squared_error, make_scorer, accuracy_score, log_loss\n",
    ")\n",
    "from sklearn import set_config, datasets\n",
    "from catboost import (\n",
    "    CatBoostRegressor, CatBoostClassifier,\n",
    ")\n",
    "# import category_encoders as ce\n",
    "# from sklearn.pipeline import (\n",
    "#     Pipeline, FeatureUnion, make_pipeline\n",
    "# )\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, StackingClassifier, StackingRegressor,\n",
    "    GradientBoostingRegressor, VotingClassifier, VotingRegressor,\n",
    "    HistGradientBoostingRegressor, GradientBoostingClassifier,\n",
    "    BaggingClassifier, AdaBoostClassifier, RandomForestRegressor,ExtraTreesRegressor\n",
    ")\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# from tpot import TPOTClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import math\n",
    "import optuna\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('matches_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2480, 29)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'home_team_result' 무 -> 승,패로 업데이트, 추가적인 기준 필요함\n",
    "# df.loc[(df['home_team_result'] == '무') & (df['home_team_shots_on_target'] >= df['away_team_shots_on_target']), 'home_team_result'] = '승'\n",
    "# df.loc[(df['home_team_result'] == '무') & (df['home_team_shots_on_target'] < df['away_team_shots_on_target']), 'home_team_result'] = '패'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature fun\n",
    "def team_encoding(train):\n",
    "    train['home_win'] = train['home_team_result'].apply(lambda x: 1 if x=='승' else 0) # home_win 열 추가, 승리인 경우 1, 아닌 경우 0\n",
    "    dic = {}\n",
    "    # 각 홈팀별 이긴 경기 수를 딕셔너리에 저장\n",
    "    for team in train['home_team_name'].unique():\n",
    "        value = train[train['home_team_name'] == team]['home_win'].sum() \n",
    "        #home_team_name  열에서 고유한 팀 이름을 가져와 각 팀이 홈에서 이긴 경기 수 계산, 이 값을 dic에 저장\n",
    "        dic[team] = value\n",
    "\n",
    "    label_dic={}\n",
    "    # 승리 횧수를 기준으로 오름차순 정렬, 각 팀에 대해 라벨 부여, 승리 횟수가 적은 팀부터 0,1,2 의 라벨을 부여\n",
    "    for idx, (team, _) in enumerate(sorted(dic.items(), key= lambda x: x[1])):\n",
    "        label_dic[team] = idx\n",
    "    \n",
    "    return label_dic\n",
    "\n",
    "\n",
    "''' 홈팀 득점 이동평균 계산 함수 '''\n",
    "\n",
    "def homeGoal_day_mean(train, test, day):\n",
    "    train[f'home_Goal_{day}_mean'] = -1  # 초기값 -1로 설정\n",
    "    test[f'home_Goal_{day}_mean'] = -1\n",
    "    \n",
    "    teams = train['home_team_name'].unique()\n",
    "    for team in tqdm(teams): # train에서 고유 팀 이름을 가져오고 이를 시각적으로 표시해줌 : tqdm\n",
    "        team_df = train[train['home_team_name'] == team]\n",
    "        # 롤링 윈도우 크기 설정\n",
    "        ch_day = len(team_df) if len(team_df) < day else day # 팀의 경기 수가 주어진 day 보다 적으면, 경기 수 만큼의 윈도우 크기 사용\n",
    "        idx = team_df['home_team_goal_count'].rolling(ch_day).mean().index.values # 롤링 윈도우 평균 계산\n",
    "        val = team_df['home_team_goal_count'].rolling(ch_day).mean().values\n",
    "        train[f'home_Goal_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['home_team_name'] == team].index\n",
    "        test[f'home_Goal_{day}_mean'].loc[test_idx] = val[-1]\n",
    "    # 결측값 처리\n",
    "    train[f'home_Goal_{day}_mean'] = train[f'home_Goal_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "''' 원정팀 득점 이동평균 계산 함수 '''\n",
    "\n",
    "def awayGoal_day_mean(train, test, day):\n",
    "    # 초기값 설정\n",
    "    train[f'away_Goal_{day}_mean'] = -1\n",
    "    test[f'away_Goal_{day}_mean'] = -1\n",
    "    \n",
    "    teams = train['away_team_name'].unique()\n",
    "    for team in tqdm(teams):\n",
    "        team_df = train[train['away_team_name'] == team]\n",
    "        # 롤링 윈도우 크기 설정\n",
    "        ch_day = len(team_df) if len(team_df) < day else day\n",
    "        idx = team_df['away_team_goal_count'].rolling(ch_day).mean().index.values\n",
    "        val = team_df['away_team_goal_count'].rolling(ch_day).mean().values\n",
    "        train[f'away_Goal_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['away_team_name'] == team].index\n",
    "        test[f'away_Goal_{day}_mean'].loc[test_idx] = val[-1]\n",
    "    # 결측값 처리\n",
    "    train[f'away_Goal_{day}_mean'] = train[f'away_Goal_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "# '''홈팀 승리율 평균 계산 함수'''\n",
    "\n",
    "# def homeWin_day_mean(train, test, day):\n",
    "#     train[f'home_winRate_{day}_mean'] = -1\n",
    "#     test[f'home_winRate_{day}_mean'] = -1\n",
    "#     train['win'] = train['home_team_result'].apply(lambda x: 1 if x == '승' else 0)\n",
    "\n",
    "#     teams = train['home_team_name'].unique()\n",
    "#     for team in tqdm(teams):\n",
    "#         team_df = train[train['home_team_name'] == team]\n",
    "#         ch_day = len(team_df) if len(team_df) < day else day\n",
    "#         idx = team_df['win'].rolling(ch_day).mean().index.values\n",
    "#         val = team_df['win'].rolling(ch_day).mean().values\n",
    "#         train[f'home_winRate_{day}_mean'].loc[idx] = val\n",
    "#         test_idx = test[test['home_team_name'] == team].index\n",
    "#         test[f'home_winRate_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "#     train.drop(columns=['win'], inplace=True)\n",
    "\n",
    "#     train[f'home_winRate_{day}_mean'] = train[f'home_winRate_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "# '''원정팀 승리율 평균 계산 함수'''\n",
    "\n",
    "# def awayWin_day_mean(train, test, day):\n",
    "\n",
    "#     train[f'away_winRate_{day}_mean'] = -1\n",
    "#     test[f'away_winRate_{day}_mean'] = -1\n",
    "#     train['win'] = train['home_team_result'].apply(lambda x: 1 if x == '패' else 0)\n",
    "    \n",
    "#     teams = train['away_team_name'].unique()\n",
    "#     for team in tqdm(teams):\n",
    "#         team_df = train[train['away_team_name'] == team]\n",
    "\n",
    "#         ch_day = len(team_df) if len(team_df) < day else day\n",
    "#         idx = team_df['win'].rolling(ch_day).mean().index.values\n",
    "#         val = team_df['win'].rolling(ch_day).mean().values\n",
    "#         train[f'away_winRate_{day}_mean'].loc[idx] = val\n",
    "#         test_idx = test[test['away_team_name'] == team].index\n",
    "#         test[f'away_winRate_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "#     train.drop(columns=['win'], inplace=True)\n",
    "\n",
    "#     train[f'away_winRate_{day}_mean'] = train[f'away_winRate_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''홈팀 평균 계산 함수'''\n",
    "\n",
    "def home_day_mean(train, test, columns, day):\n",
    "    for column in tqdm(columns):\n",
    "        teams = train['home_team_name'].values\n",
    "        train[f'home_{column}_{day}_mean'] = -1\n",
    "        test[f'home_{column}_{day}_mean'] = -1\n",
    "\n",
    "        for team in tqdm(teams):\n",
    "            team_df = train[train['home_team_name'] == team]\n",
    "            idx = team_df[column].rolling(day).mean().index.values\n",
    "            val = team_df[column].rolling(day).mean().values\n",
    "            train[f'home_{column}_{day}_mean'].loc[idx] = val\n",
    "            test_idx = test[test['home_team_name'] == team].index\n",
    "            test[f'home_{column}_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "        train[f'home_{column}_{day}_mean'] = train[f'home_{column}_{day}_mean'].fillna(0)\n",
    "        test[f'home_{column}_{day}_mean'] = test[f'home_{column}_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''원정팀 평균 계산 함수'''\n",
    "\n",
    "def away_day_mean(train, test, columns, day):\n",
    "    for column in tqdm(columns):\n",
    "        teams = train['away_team_name'].values\n",
    "        train[f'away_{column}_{day}_mean'] = -1\n",
    "        test[f'away_{column}_{day}_mean'] = -1\n",
    "\n",
    "        for team in tqdm(teams):\n",
    "            team_df = train[train['away_team_name'] == team]\n",
    "            idx = team_df[column].rolling(day).mean().index.values\n",
    "            val = team_df[column].rolling(day).mean().values\n",
    "            train[f'away_{column}_{day}_mean'].loc[idx] = val\n",
    "            test_idx = test[test['away_team_name'] == team].index\n",
    "            test[f'away_{column}_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "        train[f'away_{column}_{day}_mean'] = train[f'away_{column}_{day}_mean'].fillna(0)\n",
    "        test[f'away_{column}_{day}_mean'] = test[f'away_{column}_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''전처리 함수'''\n",
    "\n",
    "def preprocessing(train, test):\n",
    "    # 년과 월일로 나누기\n",
    "    train['date_GMT'] = train['date_GMT'].dt.strftime('%Y%m%d')\n",
    "    train['year'] = train['date_GMT'].apply(lambda x : int(x[0:4]))\n",
    "    train['date'] = train['date_GMT'].apply(lambda x : int(x[4:10]))\n",
    "    \n",
    "    test['date_GMT'] = test['date_GMT'].dt.strftime('%Y%m%d')\n",
    "    test['year'] = test['date_GMT'].apply(lambda x : int(x[0:4]))\n",
    "    test['date'] = test['date_GMT'].apply(lambda x : int(x[4:10]))\n",
    "\n",
    "    # train.drop(columns=['date_GMT'], inplace=True)\n",
    "    # test.drop(columns=['date_GMT'], inplace=True)\n",
    "\n",
    "    # # 팀 인코딩 적용   # 위에서 적용 했음\n",
    "    # label_dic = dic\n",
    "    # train['home_team_name'] = train['home_team_name'].apply(lambda x: label_dic[x])\n",
    "    # train['away_team_name'] = train['away_team_name'].apply(lambda x: label_dic[x])\n",
    "    # test['home_team_name'] = test['home_team_name'].apply(lambda x: label_dic[x])\n",
    "    # test['away_team_name'] = test['away_team_name'].apply(lambda x: label_dic[x])\n",
    "\n",
    "    # # 5일간 홈팀 승리 비율 계산    ### 이거 쓰레기인듯\n",
    "    # homeWin_day_mean(train, test, 5)\n",
    "    # # 5일간 원정팀 승리 비율 계산\n",
    "    # awayWin_day_mean(train, test, 5)\n",
    "\n",
    "    # 5일간 홈팀 평균 득점 계산\n",
    "    homeGoal_day_mean(train, test, 5)\n",
    "\n",
    "    # 5일간 원정팀 평균 득점 계산\n",
    "    awayGoal_day_mean(train, test, 5)\n",
    "\n",
    "    # 불필요한 컬럼 제거\n",
    "    train = train.drop(columns=['index','home_team_goal_count','away_team_goal_count','game_points'])\n",
    "    test = test.drop(columns=['index','home_team_goal_count','away_team_goal_count','home_team_result','game_points'])\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_label = {\n",
    "    '승' : 0,\n",
    "    '패' : 1, \n",
    "    '무' : 2,} \n",
    "    \n",
    "X = df.drop(columns=['away_team_possession'])  \n",
    "X['home_team_result'] = X['home_team_result'].map(result_label)\n",
    "y = X['home_team_result']\n",
    "# split_index = 1796 # 2021년도까지의 index\n",
    "# train = X.iloc[:split_index]\n",
    "# test = X.iloc[split_index:]\n",
    "# y_train = y.iloc[:split_index]\n",
    "# y_test = y.iloc[split_index:]\n",
    "\n",
    "# team_name 인코딩\n",
    "cat = ['home_team_name','away_team_name']\n",
    "le = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, dtype=int)\n",
    "X[cat] = le.fit_transform(X[cat])\n",
    "\n",
    "# # 승무패 인코딩\n",
    "# lec = LabelEncoder()\n",
    "# lec.fit(X['home_team_result'])\n",
    "# y = lec.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:00<00:00, 450.63it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 497.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1984, 28) (496, 27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train,Test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42) ## 이 방법에 의문을 품는 바\n",
    "\n",
    "X_train, X_val= preprocessing(X_train, X_val)\n",
    "X_val_idx = X_val.index.values\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홈팀과 원정팀의 공격 효율성을 계산한 피쳐 생성\n",
    "X_train['home_attack_efficiency'] = X_train['home_Goal_5_mean'] * X_train['home_team_shots_on_target']\n",
    "X_train['away_attack_efficiency'] = X_train['away_Goal_5_mean'] * X_train['away_team_shots_on_target']\n",
    "\n",
    "# 홈팀과 원정팀의 공격 효율성 차이를 나타내는 피쳐 생성\n",
    "X_train['attack_efficiency_difference'] = X_train['home_attack_efficiency'] - X_train['away_attack_efficiency']\n",
    "\n",
    "# 홈팀과 원정팀의 전반 골 수 차이를 나타내는 피쳐 생성\n",
    "X_train['goal_count_diff'] = X_train['home_team_goal_count_half_time'] - X_train['away_team_goal_count_half_time']\n",
    "\n",
    "# 최근 5경기 평균 득점의 표준 편차를 나타내는 피쳐 생성\n",
    "X_train['home_Goal_5_std'] = X_train['home_Goal_5_mean'].rolling(window=5).std()\n",
    "X_train['away_Goal_5_std'] = X_train['away_Goal_5_mean'].rolling(window=5).std()\n",
    "\n",
    "# 결측값을 0으로 대체\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "# 테스트 데이터에도 동일한 피쳐 생성\n",
    "X_val['home_attack_efficiency'] = X_val['home_Goal_5_mean'] * X_val['home_team_shots_on_target']\n",
    "X_val['away_attack_efficiency'] = X_val['away_Goal_5_mean'] * X_val['away_team_shots_on_target']\n",
    "X_val['attack_efficiency_difference'] = X_val['home_attack_efficiency'] - X_val['away_attack_efficiency']\n",
    "X_val['goal_count_diff'] = X_val['home_team_goal_count_half_time'] - X_val['away_team_goal_count_half_time']\n",
    "X_val['home_Goal_5_std'] = X_val['home_Goal_5_mean'].rolling(window=5).std()\n",
    "X_val['away_Goal_5_std'] = X_val['away_Goal_5_mean'].rolling(window=5).std()\n",
    "X_val = X_val.fillna(0)\n",
    "\n",
    "# 학습 데이터에서 목표 변수 'home_team_result' 컬럼 제거\n",
    "X_train.drop(columns = ['home_team_result'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "cat = ['home_team_name','away_team_name']\n",
    "\n",
    "num_features = list(set(X_train.columns) - set(cat))\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_val[num_features] = scaler.transform(X_val[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({2: 10000, 1: 10000, 0: 10000})\n",
      "Original training set shape: (1984, 33)\n",
      "Resampled training set shape: (30000, 33)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# SMOTE 객체 생성 (각 클래스의 샘플 수를 1000개로 설정)\n",
    "smote = SMOTE(sampling_strategy={0: 10000, 1: 10000, 2 : 10000}, random_state=42)\n",
    "\n",
    "# SMOTE-Tomek 객체 생성\n",
    "smote_tomek = SMOTETomek(smote=smote, random_state=42)\n",
    "\n",
    "# 오버샘플링 및 언더샘플링 적용\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# 각 클래스 비율 확인\n",
    "print(f\"Resampled class distribution: {Counter(y_train_resampled)}\")\n",
    "print(f\"Original training set shape: {X_train.shape}\")\n",
    "print(f\"Resampled training set shape: {X_train_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled['home_team_result'] = y_train_resampled\n",
    "X_val['home_team_result'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'home_team_result' 무 -> 승,패로 업데이트, 추가적인 기준 필요함\n",
    "X_train_resampled.loc[(X_train_resampled['home_team_result'] == 2) & (X_train_resampled['home_team_shots_on_target'] >= X_train_resampled['away_team_shots_on_target']), 'home_team_result'] = 0\n",
    "X_train_resampled.loc[(X_train_resampled['home_team_result'] == 2) & (X_train_resampled['home_team_shots_on_target'] < X_train_resampled['away_team_shots_on_target']), 'home_team_result'] = 1\n",
    "# 'home_team_result' 무 -> 승,패로 업데이트, 추가적인 기준 필요함\n",
    "X_val.loc[(X_val['home_team_result'] == 2) & (X_val['home_team_shots_on_target'] >= X_val['away_team_shots_on_target']), 'home_team_result'] = 0\n",
    "X_val.loc[(X_val['home_team_result'] == 2) & (X_val['home_team_shots_on_target'] < X_val['away_team_shots_on_target']), 'home_team_result'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 값 배정\n",
    "y_train_resampled = X_train_resampled['home_team_result']\n",
    "y_val = X_val['home_team_result']\n",
    "# target 값 다시 삭제\n",
    "X_train_resampled.drop(columns='home_team_result', inplace = True)\n",
    "X_val.drop(columns='home_team_result', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycaret.classification import *\n",
    "\n",
    "# setup_clf = setup(data = X_train, target = y_train, session_id = 42)\n",
    "# model = compare_models(sort = 'Accuracy', fold = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tune = tune_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(best_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8004032258064516\n",
      "Filtered SHAP Importances:\n",
      "                        column_name  shap_importance\n",
      "29    attack_efficiency_difference         1.468340\n",
      "7        home_team_shots_on_target         1.443653\n",
      "22                  5_games_result         1.334815\n",
      "8        away_team_shots_on_target         1.221697\n",
      "30                 goal_count_diff         0.985148\n",
      "17  away_team_goal_count_half_time         0.450012\n",
      "11            home_team_possession         0.274013\n",
      "24                            date         0.270088\n",
      "4           away_team_corner_count         0.267324\n",
      "5                  home_team_shots         0.243439\n",
      "28          away_attack_efficiency         0.227427\n",
      "6                  away_team_shots         0.215003\n",
      "32                 away_Goal_5_std         0.214100\n",
      "21             away_team_red_cards         0.208544\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import shap\n",
    "SHAP_THRESHOLD = 0.2\n",
    "\n",
    "# feature_names dimension 조정\n",
    "X_train_col = X_train.columns\n",
    "feature_names = X_train_col.to_numpy()\n",
    "\n",
    "# 모델 학습\n",
    "model = xgb.XGBClassifier().fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 모델 예측 및 평가\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# SHAP 값 계산\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "# SHAP 값 요약\n",
    "if isinstance(shap_values, list):  # shap_values가 리스트일 경우 (XGBoost >= 1.0.0)\n",
    "    shap_values = shap_values[1]\n",
    "\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame({'column_name': feature_names, 'shap_importance': shap_sum})\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "\n",
    "# 중요도 임계값 적용 (선택 사항)\n",
    "importance_df_filtered = importance_df[importance_df['shap_importance'] > SHAP_THRESHOLD]\n",
    "print(\"Filtered SHAP Importances:\\n\", importance_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된(SHAP_THRESHOLD) Shap feature 중요도 이상인 것만 선택\n",
    "features_selected = importance_df.query('shap_importance > @SHAP_THRESHOLD').column_name.tolist()\n",
    "shap_xgb_X_train_resampled = X_train_resampled[features_selected]\n",
    "shap_xgb_X_val = X_val[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LightGBM 모델 학습\n",
    "# model = lgb.LGBMClassifier().fit(X_train_resampled, y_train_resampled)\n",
    "# SHAP_THRESHOLD = 0.3\n",
    "\n",
    "# # 모델 예측 및 평가\n",
    "# y_pred = model.predict(X_val)\n",
    "# print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# # SHAP 값 계산\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "# shap_sum = np.abs(shap_values).mean(axis=1)[1,:]\n",
    "# importance_df = pd.DataFrame([X_val.columns.tolist(), shap_sum.tolist()]).T\n",
    "# importance_df.columns = ['column_name', 'shap_importance']\n",
    "# importance_df = importance_df.sort_values('shap_importance', ascending=False);\n",
    "# importance_df\n",
    "\n",
    "# # SHAP 값 데이터프레임 생성 (각 피쳐별 SHAP 값)\n",
    "# shap_values_df = pd.DataFrame(shap_values[1], columns=X_val.columns)\n",
    "# shap_values_df\n",
    "\n",
    "# # SHAP 값의 평균 절대값 계산\n",
    "# shap_abs_mean = pd.DataFrame(shap_values[1], columns=X_val.columns).abs().mean().sort_values(ascending=False)\n",
    "\n",
    "# # SHAP 값 평균 절대값 시각화\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# shap_abs_mean.plot(kind='barh')\n",
    "# plt.title(\"Mean Absolute SHAP Values for Features\")\n",
    "# plt.xlabel(\"Mean Absolute SHAP Value\")\n",
    "# plt.ylabel(\"Features\")\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 지정된(SHAP_THRESHOLD) Shap feature 중요도 이상인 것만 선택\n",
    "# features_selected = importance_df.query('shap_importance > @SHAP_THRESHOLD').column_name.tolist()\n",
    "# shap_lgbm_X_train_resampled = X_train_resampled[features_selected]\n",
    "# shap_lgbm_X_val = X_val[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oputna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgboostclassifier\n",
    "# import optuna\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# def xgb_objective(trial):\n",
    "#     # 하이퍼파라미터 범위 설정\n",
    "#     max_depth = trial.suggest_int('max_depth', 3, 7)  # max_depth의 범위를 줄임\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 50, 200)  # n_estimators의 범위를 줄임\n",
    "#     subsample = trial.suggest_float('subsample', 0.5, 0.9)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 0.9)\n",
    "#     min_child_weight = trial.suggest_int('min_child_weight', 4, 10)  # 추가\n",
    "#     gamma = trial.suggest_float('gamma', 0, 5)  # 추가\n",
    "    \n",
    "#     # XGBClassifier 모델 정의\n",
    "#     clf = XGBClassifier(\n",
    "#         max_depth=max_depth,\n",
    "#         learning_rate=learning_rate,\n",
    "#         n_estimators=n_estimators,\n",
    "#         subsample=subsample,\n",
    "#         colsample_bytree=colsample_bytree,\n",
    "#         min_child_weight=min_child_weight,  # 추가\n",
    "#         gamma=gamma,  # 추가\n",
    "#         use_label_encoder=False,\n",
    "#         eval_metric='logloss'\n",
    "#     )\n",
    "    \n",
    "#     # 교차 검증 점수 계산\n",
    "#     scores = cross_val_score(clf, shap_xgb_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "#     return scores.mean()\n",
    "\n",
    "# # Optuna 스터디 생성 및 최적화\n",
    "# xgb_study = optuna.create_study(direction='maximize')\n",
    "# xgb_study.optimize(xgb_objective, n_trials=50)  # 최적화 반복 횟수는 필요에 따라 조절\n",
    "\n",
    "# # 최적 하이퍼파라미터 출력\n",
    "# xgb_best_params = xgb_study.best_params\n",
    "# print(' ')\n",
    "# print(xgb_study.best_value)\n",
    "# print(xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_logis=xgb.XGBClassifier(**xgb_best_params)\n",
    "# # model_logis=xgb.XGBClassifier(max_depth= 4, learning_rate= 0.00020353095689003422, n_estimators= 229, subsample= 0.5217582675029752, colsample_bytree= 0.5421399627551824)\n",
    "# model_logis.fit(shap_xgb_X_train_resampled, y_train_resampled)\n",
    "# y_pred = model_logis.predict(shap_xgb_X_val)\n",
    "\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy=\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LogisticRegression\n",
    "# def logreg_objective(trial):\n",
    "\n",
    "#     r = trial.suggest_float('l1_ratio', 0.3, 0.8, log=False)  # 범위를 0.1에서 0.9로 좁힘\n",
    "#     c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "#     max_iter = trial.suggest_int('max_iter', 500, 2000, step=500)  # max_iter 튜닝 추가\n",
    "    \n",
    "#     clf =  LogisticRegression(max_iter=max_iter, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "#     scores = cross_val_score(clf, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "#     return scores.mean()\n",
    "    \n",
    "# logreg_study = optuna.create_study(direction='maximize')\n",
    "# logreg_study.optimize(logreg_objective, n_trials=20)\n",
    "\n",
    "# logreg_best_params = logreg_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_logis=LogisticRegression(**logreg_best_params)\n",
    "# model_logis.fit(X_train_resampled,y_train_resampled)\n",
    "# y_pred = model_logis.predict(X_val)\n",
    "\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-11 18:05:14,745] A new study created in memory with name: no-name-6ae32a38-fe00-43a1-8394-de40f21b2253\n",
      "[I 2024-07-11 18:05:14,896] Trial 0 finished with value: 0.8979176103684884 and parameters: {'alpha': 1.4572312423496807}. Best is trial 0 with value: 0.8979176103684884.\n",
      "[I 2024-07-11 18:05:15,054] Trial 1 finished with value: 0.8979166489581761 and parameters: {'alpha': 1.043596960600737}. Best is trial 0 with value: 0.8979176103684884.\n",
      "[I 2024-07-11 18:05:15,212] Trial 2 finished with value: 0.8979159278965598 and parameters: {'alpha': 0.0022591072091080354}. Best is trial 0 with value: 0.8979176103684884.\n",
      "[I 2024-07-11 18:05:15,378] Trial 3 finished with value: 0.8979160347199278 and parameters: {'alpha': 0.019080447362521666}. Best is trial 0 with value: 0.8979176103684884.\n",
      "[I 2024-07-11 18:05:15,576] Trial 4 finished with value: 0.8979591379452462 and parameters: {'alpha': 43.12699938475891}. Best is trial 4 with value: 0.8979591379452462.\n",
      "[I 2024-07-11 18:05:15,732] Trial 5 finished with value: 0.8979159278965598 and parameters: {'alpha': 6.605355002656814e-05}. Best is trial 4 with value: 0.8979591379452462.\n",
      "[I 2024-07-11 18:05:15,896] Trial 6 finished with value: 0.8979159278965598 and parameters: {'alpha': 0.0007774239103607727}. Best is trial 4 with value: 0.8979591379452462.\n",
      "[I 2024-07-11 18:05:16,069] Trial 7 finished with value: 0.8979159278965598 and parameters: {'alpha': 0.004352975883093971}. Best is trial 4 with value: 0.8979591379452462.\n",
      "[I 2024-07-11 18:05:16,231] Trial 8 finished with value: 0.8979162750743449 and parameters: {'alpha': 0.08189033027784008}. Best is trial 4 with value: 0.8979591379452462.\n",
      "[I 2024-07-11 18:05:16,388] Trial 9 finished with value: 0.8985312581733765 and parameters: {'alpha': 833.8624771512078}. Best is trial 9 with value: 0.8985312581733765.\n",
      "[I 2024-07-11 18:05:16,563] Trial 10 finished with value: 0.8985439168123674 and parameters: {'alpha': 856.658834255412}. Best is trial 10 with value: 0.8985439168123674.\n",
      "[I 2024-07-11 18:05:16,769] Trial 11 finished with value: 0.8983511000797669 and parameters: {'alpha': 543.266708402652}. Best is trial 10 with value: 0.8985439168123674.\n",
      "[I 2024-07-11 18:05:16,954] Trial 12 finished with value: 0.8985739075446588 and parameters: {'alpha': 919.9245906533224}. Best is trial 12 with value: 0.8985739075446588.\n",
      "[I 2024-07-11 18:05:17,133] Trial 13 finished with value: 0.8979405239747988 and parameters: {'alpha': 22.943903941278666}. Best is trial 12 with value: 0.8985739075446588.\n",
      "[I 2024-07-11 18:05:17,304] Trial 14 finished with value: 0.8979540905572493 and parameters: {'alpha': 37.69539536783289}. Best is trial 12 with value: 0.8985739075446588.\n",
      "[I 2024-07-11 18:05:17,486] Trial 15 finished with value: 0.8979192928314266 and parameters: {'alpha': 3.0010457595162894}. Best is trial 12 with value: 0.8985739075446588.\n",
      "[I 2024-07-11 18:05:17,658] Trial 16 finished with value: 0.898133206783221 and parameters: {'alpha': 227.67648292894853}. Best is trial 12 with value: 0.8985739075446588.\n",
      "[I 2024-07-11 18:05:17,812] Trial 17 finished with value: 0.897923993048177 and parameters: {'alpha': 7.569437431116655}. Best is trial 12 with value: 0.8985739075446588.\n",
      "[I 2024-07-11 18:05:17,965] Trial 18 finished with value: 0.8980354098782346 and parameters: {'alpha': 118.60686176603708}. Best is trial 12 with value: 0.8985739075446588.\n",
      "[I 2024-07-11 18:05:18,113] Trial 19 finished with value: 0.8979160347199279 and parameters: {'alpha': 0.1841558610049465}. Best is trial 12 with value: 0.8985739075446588.\n",
      "[I 2024-07-11 18:05:18,262] Trial 20 finished with value: 0.8980238195391262 and parameters: {'alpha': 108.02979643536558}. Best is trial 12 with value: 0.8985739075446588.\n",
      "[I 2024-07-11 18:05:18,417] Trial 21 finished with value: 0.8986030437504873 and parameters: {'alpha': 979.0952004022884}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:18,582] Trial 22 finished with value: 0.898599011158741 and parameters: {'alpha': 967.4788794371005}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:18,760] Trial 23 finished with value: 0.8979271443420291 and parameters: {'alpha': 10.60366337480047}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:18,947] Trial 24 finished with value: 0.8981348091345586 and parameters: {'alpha': 229.50450522345943}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:19,139] Trial 25 finished with value: 0.8979736926040064 and parameters: {'alpha': 58.29312735839118}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:19,287] Trial 26 finished with value: 0.8985091991131443 and parameters: {'alpha': 795.242687665846}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:19,435] Trial 27 finished with value: 0.8981096789125079 and parameters: {'alpha': 202.89663127588247}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:19,597] Trial 28 finished with value: 0.8979159278965598 and parameters: {'alpha': 3.876236807309349e-05}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:19,752] Trial 29 finished with value: 0.8979165154279446 and parameters: {'alpha': 0.8195247863876473}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:19,911] Trial 30 finished with value: 0.8979361174796058 and parameters: {'alpha': 19.244047499042402}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:20,068] Trial 31 finished with value: 0.8983763371513397 and parameters: {'alpha': 575.7099609219838}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:20,214] Trial 32 finished with value: 0.8984663361155588 and parameters: {'alpha': 717.6366248056164}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:20,371] Trial 33 finished with value: 0.8981089845659285 and parameters: {'alpha': 201.8377828811246}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:20,520] Trial 34 finished with value: 0.8979191325976004 and parameters: {'alpha': 2.6008282437362005}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:20,675] Trial 35 finished with value: 0.8979159278965598 and parameters: {'alpha': 1.0132183351538071e-05}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:20,821] Trial 36 finished with value: 0.8979818111995916 and parameters: {'alpha': 67.6677150920194}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:20,973] Trial 37 finished with value: 0.8985895305466197 and parameters: {'alpha': 951.9294011791837}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:21,129] Trial 38 finished with value: 0.8981678176329221 and parameters: {'alpha': 278.9007521076678}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:21,308] Trial 39 finished with value: 0.8979161949586579 and parameters: {'alpha': 0.349754536345088}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:21,472] Trial 40 finished with value: 0.8979159813086525 and parameters: {'alpha': 0.011091247310085801}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:21,627] Trial 41 finished with value: 0.8985886759457812 and parameters: {'alpha': 949.3394244569797}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:21,774] Trial 42 finished with value: 0.8982443833520355 and parameters: {'alpha': 379.59899315747026}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:21,929] Trial 43 finished with value: 0.8980196534204178 and parameters: {'alpha': 104.85705349526478}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:22,085] Trial 44 finished with value: 0.8979159278965598 and parameters: {'alpha': 0.0007268674448924235}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:22,269] Trial 45 finished with value: 0.8986017618741576 and parameters: {'alpha': 977.5506843264544}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:22,445] Trial 46 finished with value: 0.8979438889121177 and parameters: {'alpha': 26.020954355294478}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:22,622] Trial 47 finished with value: 0.8982234726452573 and parameters: {'alpha': 350.656761351225}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:22,783] Trial 48 finished with value: 0.8979241532836376 and parameters: {'alpha': 7.758260415687218}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:22,930] Trial 49 finished with value: 0.8980402703647729 and parameters: {'alpha': 124.2095471756701}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:23,077] Trial 50 finished with value: 0.8979161415449307 and parameters: {'alpha': 0.054524097326328}. Best is trial 21 with value: 0.8986030437504873.\n",
      "[I 2024-07-11 18:05:23,230] Trial 51 finished with value: 0.8986104946826542 and parameters: {'alpha': 998.8631237057213}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:23,373] Trial 52 finished with value: 0.8985753496597183 and parameters: {'alpha': 923.7333175065401}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:23,550] Trial 53 finished with value: 0.8982718102711861 and parameters: {'alpha': 426.0630759679783}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:23,715] Trial 54 finished with value: 0.8979709419033016 and parameters: {'alpha': 55.46150420574174}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:23,868] Trial 55 finished with value: 0.8983064478506356 and parameters: {'alpha': 474.93377655282507}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:24,022] Trial 56 finished with value: 0.8980715963135625 and parameters: {'alpha': 158.53610083988855}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:24,177] Trial 57 finished with value: 0.8985703022521058 and parameters: {'alpha': 910.189607113753}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:24,322] Trial 58 finished with value: 0.8982330867598214 and parameters: {'alpha': 362.11774209820027}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:24,484] Trial 59 finished with value: 0.8979993569240992 and parameters: {'alpha': 84.74982979275113}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:24,645] Trial 60 finished with value: 0.8979570816009287 and parameters: {'alpha': 40.830812264579066}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:24,798] Trial 61 finished with value: 0.8986087053930789 and parameters: {'alpha': 991.213430707036}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:24,946] Trial 62 finished with value: 0.8985909459580849 and parameters: {'alpha': 954.4925846390278}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:25,099] Trial 63 finished with value: 0.8981132307978722 and parameters: {'alpha': 206.29163622134072}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:25,257] Trial 64 finished with value: 0.8983105605384534 and parameters: {'alpha': 479.6615971596777}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:25,408] Trial 65 finished with value: 0.8982056064130494 and parameters: {'alpha': 328.70145005483255}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:25,562] Trial 66 finished with value: 0.8979318712819891 and parameters: {'alpha': 15.679820175310299}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:25,730] Trial 67 finished with value: 0.8980773380791973 and parameters: {'alpha': 164.2105767776656}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:25,928] Trial 68 finished with value: 0.8983990638897019 and parameters: {'alpha': 608.377754010606}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:26,099] Trial 69 finished with value: 0.898175001520972 and parameters: {'alpha': 287.28182658473355}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:26,271] Trial 70 finished with value: 0.8979954845866116 and parameters: {'alpha': 81.64320638953546}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:26,429] Trial 71 finished with value: 0.898552409291784 and parameters: {'alpha': 872.8823400356955}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:26,607] Trial 72 finished with value: 0.8986089724551768 and parameters: {'alpha': 991.591509925807}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:26,769] Trial 73 finished with value: 0.8983299757164448 and parameters: {'alpha': 515.608861761359}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:26,924] Trial 74 finished with value: 0.8980811837171768 and parameters: {'alpha': 171.7710201019049}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:27,071] Trial 75 finished with value: 0.8983769780948171 and parameters: {'alpha': 576.1373803286566}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:27,258] Trial 76 finished with value: 0.8986096133970195 and parameters: {'alpha': 993.7706176972007}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:27,411] Trial 77 finished with value: 0.8981760964549773 and parameters: {'alpha': 288.99898515925673}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:27,565] Trial 78 finished with value: 0.8983570020636985 and parameters: {'alpha': 552.9237323007474}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:27,722] Trial 79 finished with value: 0.8980542642120892 and parameters: {'alpha': 141.4246139507834}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:27,875] Trial 80 finished with value: 0.8986044324477329 and parameters: {'alpha': 983.565095065207}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:28,048] Trial 81 finished with value: 0.8981465062978519 and parameters: {'alpha': 246.60678283553665}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:28,216] Trial 82 finished with value: 0.8983742006880661 and parameters: {'alpha': 573.4468576817324}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:28,364] Trial 83 finished with value: 0.898558418130959 and parameters: {'alpha': 889.9576823781657}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:28,533] Trial 84 finished with value: 0.8979159278965598 and parameters: {'alpha': 0.0003952909320121074}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:28,737] Trial 85 finished with value: 0.8982395228671317 and parameters: {'alpha': 373.0850902043113}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:28,910] Trial 86 finished with value: 0.8986089724576288 and parameters: {'alpha': 989.8179711694032}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:29,115] Trial 87 finished with value: 0.8981501116010301 and parameters: {'alpha': 251.7803069356088}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:29,300] Trial 88 finished with value: 0.8980342615182422 and parameters: {'alpha': 118.13644793526798}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:29,483] Trial 89 finished with value: 0.898408651332547 and parameters: {'alpha': 621.285269998134}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:29,679] Trial 90 finished with value: 0.8979472538739556 and parameters: {'alpha': 30.26855664546601}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:29,858] Trial 91 finished with value: 0.8985908658391285 and parameters: {'alpha': 954.5703939432203}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:30,030] Trial 92 finished with value: 0.898241312159159 and parameters: {'alpha': 375.82429648440353}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:30,241] Trial 93 finished with value: 0.8986088923362207 and parameters: {'alpha': 990.498518408494}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:30,445] Trial 94 finished with value: 0.8983711829056474 and parameters: {'alpha': 570.1643483468692}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:30,608] Trial 95 finished with value: 0.8982560805006173 and parameters: {'alpha': 397.6619594498242}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:30,772] Trial 96 finished with value: 0.8981316845459357 and parameters: {'alpha': 226.52610163109065}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:30,938] Trial 97 finished with value: 0.8984405114848125 and parameters: {'alpha': 671.8114529157111}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:31,098] Trial 98 finished with value: 0.8979658410852309 and parameters: {'alpha': 50.58278946348469}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:31,267] Trial 99 finished with value: 0.8979993836301453 and parameters: {'alpha': 84.85587786116999}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:31,435] Trial 100 finished with value: 0.8985998123393139 and parameters: {'alpha': 968.7988393487958}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:31,595] Trial 101 finished with value: 0.898603791515698 and parameters: {'alpha': 979.9582114151978}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:31,762] Trial 102 finished with value: 0.8984518348190349 and parameters: {'alpha': 693.3161084187731}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:31,926] Trial 103 finished with value: 0.898605473985992 and parameters: {'alpha': 985.1106858897994}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:32,092] Trial 104 finished with value: 0.8982451845301562 and parameters: {'alpha': 382.5713949419218}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:32,251] Trial 105 finished with value: 0.8980940292437318 and parameters: {'alpha': 185.03751428861725}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:32,421] Trial 106 finished with value: 0.8982754155596525 and parameters: {'alpha': 431.61039850126537}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:32,619] Trial 107 finished with value: 0.8984674577605144 and parameters: {'alpha': 720.2853001241541}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:32,793] Trial 108 finished with value: 0.8981721172785929 and parameters: {'alpha': 284.6307296632032}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:32,946] Trial 109 finished with value: 0.8979161148372495 and parameters: {'alpha': 0.02984538020961726}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:33,119] Trial 110 finished with value: 0.8979159278965598 and parameters: {'alpha': 0.006467087075641728}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:33,291] Trial 111 finished with value: 0.8984492710467599 and parameters: {'alpha': 688.700861788718}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:33,462] Trial 112 finished with value: 0.8985876611299147 and parameters: {'alpha': 946.3095414301139}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:33,635] Trial 113 finished with value: 0.8982999316055708 and parameters: {'alpha': 466.2228010036605}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:33,789] Trial 114 finished with value: 0.8979163017812087 and parameters: {'alpha': 0.709552223405483}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:33,941] Trial 115 finished with value: 0.8984262772577424 and parameters: {'alpha': 653.1877874058374}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:34,091] Trial 116 finished with value: 0.898174707758549 and parameters: {'alpha': 286.8298800826127}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:34,244] Trial 117 finished with value: 0.8985913465479626 and parameters: {'alpha': 954.2576638367277}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:34,402] Trial 118 finished with value: 0.8980610207878689 and parameters: {'alpha': 148.87805988518684}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:34,548] Trial 119 finished with value: 0.8982938426539779 and parameters: {'alpha': 455.7511978812639}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:34,709] Trial 120 finished with value: 0.8985977826863308 and parameters: {'alpha': 964.9650588528992}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:34,882] Trial 121 finished with value: 0.8984208826658063 and parameters: {'alpha': 646.7179005207329}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:35,048] Trial 122 finished with value: 0.8986098804583004 and parameters: {'alpha': 995.5807972364233}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:35,200] Trial 123 finished with value: 0.8986095065711998 and parameters: {'alpha': 994.1804703231508}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:35,350] Trial 124 finished with value: 0.898320975830321 and parameters: {'alpha': 499.4768044351705}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:35,497] Trial 125 finished with value: 0.8981316578366202 and parameters: {'alpha': 226.34393165219853}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:35,649] Trial 126 finished with value: 0.8981956718308329 and parameters: {'alpha': 313.5120150279217}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:35,803] Trial 127 finished with value: 0.8979203076513794 and parameters: {'alpha': 3.7747997476461044}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:35,958] Trial 128 finished with value: 0.8984158352508378 and parameters: {'alpha': 637.9071899735158}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:36,110] Trial 129 finished with value: 0.8982592317773056 and parameters: {'alpha': 403.36547539103606}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:36,265] Trial 130 finished with value: 0.8986098270453904 and parameters: {'alpha': 996.007211528284}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:36,419] Trial 131 finished with value: 0.8986050199807525 and parameters: {'alpha': 984.422103215023}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:36,578] Trial 132 finished with value: 0.8984406717243597 and parameters: {'alpha': 672.9799359266602}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:36,758] Trial 133 finished with value: 0.8983546252582674 and parameters: {'alpha': 548.6136132836095}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:36,930] Trial 134 finished with value: 0.8986080110415955 and parameters: {'alpha': 988.8125047685188}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:37,117] Trial 135 finished with value: 0.8982098259438506 and parameters: {'alpha': 335.16277340399324}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:37,286] Trial 136 finished with value: 0.8984796890798791 and parameters: {'alpha': 734.8341061671337}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:37,435] Trial 137 finished with value: 0.8983106139505459 and parameters: {'alpha': 480.10598220564236}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:37,616] Trial 138 finished with value: 0.8986006936323042 and parameters: {'alpha': 973.5074737379451}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:37,769] Trial 139 finished with value: 0.8981436754978066 and parameters: {'alpha': 239.9851965817815}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:37,920] Trial 140 finished with value: 0.8986089724543596 and parameters: {'alpha': 991.5529522845306}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:38,077] Trial 141 finished with value: 0.898440591599682 and parameters: {'alpha': 672.352565225199}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:38,232] Trial 142 finished with value: 0.8982805698274122 and parameters: {'alpha': 438.27627291583076}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:38,384] Trial 143 finished with value: 0.8985801033269754 and parameters: {'alpha': 930.8538950611181}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:38,544] Trial 144 finished with value: 0.8983145397189243 and parameters: {'alpha': 489.0437318496217}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:38,707] Trial 145 finished with value: 0.8979160614259741 and parameters: {'alpha': 0.15825583491651762}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:38,859] Trial 146 finished with value: 0.8982022414732788 and parameters: {'alpha': 323.2646165349463}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:39,014] Trial 147 finished with value: 0.8986089724535423 and parameters: {'alpha': 990.8609861407289}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:39,171] Trial 148 finished with value: 0.8984569890532846 and parameters: {'alpha': 701.0745025370294}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:39,343] Trial 149 finished with value: 0.8980923200714782 and parameters: {'alpha': 183.23203994093097}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:39,510] Trial 150 finished with value: 0.8986070229309583 and parameters: {'alpha': 986.9529154199658}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:39,669] Trial 151 finished with value: 0.8984404847779489 and parameters: {'alpha': 671.941477327813}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:39,822] Trial 152 finished with value: 0.898608972452725 and parameters: {'alpha': 992.3814723745978}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:39,974] Trial 153 finished with value: 0.8983529962000664 and parameters: {'alpha': 545.3758717121566}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:40,124] Trial 154 finished with value: 0.8986088923362207 and parameters: {'alpha': 990.1951531938216}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:40,300] Trial 155 finished with value: 0.898237653463504 and parameters: {'alpha': 369.59009339077204}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:40,531] Trial 156 finished with value: 0.8983318718383786 and parameters: {'alpha': 517.5927708893703}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:40,698] Trial 157 finished with value: 0.8979159278965598 and parameters: {'alpha': 0.0021873725563178853}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:40,860] Trial 158 finished with value: 0.8984494312830379 and parameters: {'alpha': 688.3150721479147}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:41,005] Trial 159 finished with value: 0.8981822121052607 and parameters: {'alpha': 294.3604221095606}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:41,152] Trial 160 finished with value: 0.8982960592451987 and parameters: {'alpha': 461.0778224764872}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:41,312] Trial 161 finished with value: 0.8985837086309708 and parameters: {'alpha': 936.8498220501976}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:41,466] Trial 162 finished with value: 0.8985892634820697 and parameters: {'alpha': 951.0995982447292}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:41,650] Trial 163 finished with value: 0.8984589919904136 and parameters: {'alpha': 705.9644114744441}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:41,816] Trial 164 finished with value: 0.8985925750146516 and parameters: {'alpha': 958.1752042193518}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:41,974] Trial 165 finished with value: 0.8984083041563967 and parameters: {'alpha': 620.565065195486}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:42,121] Trial 166 finished with value: 0.8986068092858567 and parameters: {'alpha': 986.281914016737}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:42,274] Trial 167 finished with value: 0.8982461192352394 and parameters: {'alpha': 380.7764477276637}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:42,425] Trial 168 finished with value: 0.8983152875004814 and parameters: {'alpha': 491.05603024685684}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:42,588] Trial 169 finished with value: 0.8979159278965598 and parameters: {'alpha': 9.859616310185361e-05}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:42,744] Trial 170 finished with value: 0.898448549983509 and parameters: {'alpha': 687.3671481138082}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:42,896] Trial 171 finished with value: 0.8986099071635293 and parameters: {'alpha': 996.0289634738995}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:43,052] Trial 172 finished with value: 0.8984516211722987 and parameters: {'alpha': 693.1132667169583}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:43,204] Trial 173 finished with value: 0.898303163010206 and parameters: {'alpha': 471.1287445896823}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:43,360] Trial 174 finished with value: 0.8984647070491844 and parameters: {'alpha': 714.3635100149436}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:43,510] Trial 175 finished with value: 0.8986100941042189 and parameters: {'alpha': 995.0011322746523}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:43,666] Trial 176 finished with value: 0.898193214897455 and parameters: {'alpha': 309.17915454988656}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:43,837] Trial 177 finished with value: 0.8985998924533661 and parameters: {'alpha': 971.5302839082706}. Best is trial 51 with value: 0.8986104946826542.\n",
      "[I 2024-07-11 18:05:44,037] Trial 178 finished with value: 0.898610921977761 and parameters: {'alpha': 999.3666245183015}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:44,218] Trial 179 finished with value: 0.8983125901889842 and parameters: {'alpha': 483.8340781554449}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:44,389] Trial 180 finished with value: 0.8981398298426634 and parameters: {'alpha': 235.62659805697317}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:44,544] Trial 181 finished with value: 0.8984028561237617 and parameters: {'alpha': 612.3375627802537}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:44,696] Trial 182 finished with value: 0.8985997856332674 and parameters: {'alpha': 968.3048957017565}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:44,855] Trial 183 finished with value: 0.8986098804493099 and parameters: {'alpha': 997.7737982972127}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:45,010] Trial 184 finished with value: 0.8983945506038332 and parameters: {'alpha': 603.752675348016}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:45,161] Trial 185 finished with value: 0.8984555469365905 and parameters: {'alpha': 698.3816836602376}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:45,319] Trial 186 finished with value: 0.8982397365163197 and parameters: {'alpha': 373.7479434673499}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:45,474] Trial 187 finished with value: 0.8983217235759163 and parameters: {'alpha': 501.8826300195457}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:45,634] Trial 188 finished with value: 0.8984678049309437 and parameters: {'alpha': 720.6784388810439}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:45,790] Trial 189 finished with value: 0.8985990111587411 and parameters: {'alpha': 967.2210834751365}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:45,937] Trial 190 finished with value: 0.8982580834377462 and parameters: {'alpha': 401.5019318054573}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:46,095] Trial 191 finished with value: 0.8986020556390327 and parameters: {'alpha': 977.7753113886974}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:46,272] Trial 192 finished with value: 0.8986088656301744 and parameters: {'alpha': 990.3618619635228}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:46,420] Trial 193 finished with value: 0.8984354106691939 and parameters: {'alpha': 662.318229364753}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:46,570] Trial 194 finished with value: 0.8983445838494138 and parameters: {'alpha': 534.6425148743431}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:46,730] Trial 195 finished with value: 0.8986089190422669 and parameters: {'alpha': 990.4848484161259}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:46,891] Trial 196 finished with value: 0.8984477487988496 and parameters: {'alpha': 685.0096698126175}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:47,048] Trial 197 finished with value: 0.8986098270453904 and parameters: {'alpha': 995.9778335206386}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:47,226] Trial 198 finished with value: 0.8982440094657522 and parameters: {'alpha': 379.1618683961211}. Best is trial 178 with value: 0.898610921977761.\n",
      "[I 2024-07-11 18:05:47,378] Trial 199 finished with value: 0.8984355976139701 and parameters: {'alpha': 662.0868245056877}. Best is trial 178 with value: 0.898610921977761.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ridge Classifier의 목적 함수\n",
    "def ridge_classifier_objective(trial):\n",
    "\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e3, log=True)\n",
    "    clf = RidgeClassifier(alpha=alpha)\n",
    "    \n",
    "    # 교차 검증을 통한 모델 평가 (AUC 스코어)\n",
    "    # 다중 클래스의 경우, 'ovr' 또는 'ovo' 스키마를 사용\n",
    "    # if len(set(y_train_resampled)) > 2:\n",
    "    #     scoring = 'roc_auc_ovr'\n",
    "    # else:\n",
    "    #     scoring = 'roc_auc'\n",
    "    \n",
    "    scores = cross_val_score(clf, shap_xgb_X_train_resampled, y_train_resampled, cv=6, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "ridge_classifier_study = optuna.create_study(direction='maximize')\n",
    "ridge_classifier_study.optimize(ridge_classifier_objective, n_trials=200)\n",
    "ridge_classifier_best_params = ridge_classifier_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 최적의 하이퍼파라미터로 최종 모델 학습 및 평가\n",
    "# model_ridge_classifier = RidgeClassifier(**ridge_classifier_best_params)\n",
    "# model_ridge_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# # 검증 데이터로 예측\n",
    "# y_pred = model_ridge_classifier.predict(X_val)\n",
    "\n",
    "# # 정확도 계산\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8875584445204698\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터로 최종 모델 학습 및 평가\n",
    "model_ridge_classifier = RidgeClassifier(**ridge_classifier_best_params)\n",
    "model_ridge_classifier.fit(shap_xgb_X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 검증 데이터로 예측\n",
    "y_pred = model_ridge_classifier.predict(shap_xgb_X_val)\n",
    "y_pred_proba = model_ridge_classifier.decision_function(shap_xgb_X_val)\n",
    "\n",
    "# 다중 클래스의 경우 ROC AUC 스코어 계산\n",
    "if len(set(y_val)) > 2:\n",
    "    y_val_bin = label_binarize(y_val, classes=list(set(y_val)))\n",
    "    auc_score = roc_auc_score(y_val_bin, y_pred_proba, multi_class='ovr')\n",
    "else:\n",
    "    auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "print(\"AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis=LogisticRegression(l1_ratio= 0.789370019111903, C= 0.07701480047825814, max_iter= 1000)\n",
    "model_logis.fit(X_train_resampled,y_train_resampled)\n",
    "y_pred = model_logis.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomforest feature selection  큰 효과가 없는 듯 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier()\n",
    "# model.fit(train_resampled, y_train_resampled)\n",
    "# y_pred = model.predict(test)\n",
    "\n",
    "# rn_features = []\n",
    "# importances = model.feature_importances_\n",
    "# feature_names = train.columns\n",
    "\n",
    "# # 피처 중요도를 기준으로 정렬하여 상위 피처 선택\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # 중요도가 0.01 이상인 피처만 선택\n",
    "# # top_number = 40\n",
    "# top_num_indices = [idx for idx in indices if importances[idx] >= 0.005] #[:top_number]\n",
    "# top_features = feature_names[top_num_indices]\n",
    "\n",
    "# for i, feature in enumerate(top_features):\n",
    "#     print(f\"{i+1}. {feature} (중요도: {importances[top_num_indices[i]]})\")\n",
    "#     rn_features.append(feature)\n",
    "\n",
    "# rn_train_resampled = train_resampled[rn_features]\n",
    "# rn_test = test[rn_features]\n",
    "\n",
    "# model_logis=LogisticRegression(**logreg_best_params)\n",
    "# model_logis.fit(rn_train_resampled,y_train_resampled)\n",
    "# y_pred = model_logis.predict(rn_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관계수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "corr_number = 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > corr_number)]\n",
    "to_drop\n",
    "# # 특징 제거\n",
    "corr_X_train_resampled = X_train_resampled.drop(columns=to_drop)  \n",
    "corr_X_val = X_val.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_objective(trial):\n",
    "    \n",
    "    r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "     \n",
    "    clf =  LogisticRegression(max_iter=5000, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "    scores = cross_val_score(clf, corr_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "logreg_study = optuna.create_study(direction='maximize')\n",
    "logreg_study.optimize(logreg_objective, n_trials=5)\n",
    "\n",
    "logreg_best_params = logreg_study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis=LogisticRegression(**logreg_best_params)\n",
    "model_logis.fit(corr_X_train_resampled,y_train_resampled)\n",
    "y_pred = model_logis.predict(corr_X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 규제(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 값 후보군 설정\n",
    "alpha_values = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 100]\n",
    "param_grid = {'alpha': alpha_values}\n",
    "\n",
    "# Lasso 모델과 GridSearchCV 설정\n",
    "lasso = Lasso()\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# 최적의 alpha 값 찾기\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=best_alpha)  # 위에서 나온 alpha 값으로 조정한 거임\n",
    "lasso.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 가중치가 0이 아닌 특징 선택\n",
    "selected_features = X_train_resampled.columns[lasso.coef_ != 0]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_X_train_resampled = X_train_resampled[selected_features]\n",
    "L1_X_val = X_val[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_objective(trial):\n",
    "    \n",
    "    r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "     \n",
    "    clf =  LogisticRegression(max_iter=5000, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "    scores = cross_val_score(clf, L1_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "logreg_study = optuna.create_study(direction='maximize')\n",
    "logreg_study.optimize(logreg_objective, n_trials=5)\n",
    "\n",
    "logreg_best_params = logreg_study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2013~2023  \n",
    "### 많긴 하지만 정확도 떨어질 것으로 예상됨\n",
    "\n",
    "# 2020~2023\n",
    "### 데이터 수가 급격히 줄어듬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
