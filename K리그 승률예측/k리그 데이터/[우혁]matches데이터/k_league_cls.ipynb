{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from matplotlib import font_manager, rc\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "# from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, PowerTransformer, OrdinalEncoder,\n",
    "    OneHotEncoder, FunctionTransformer, PolynomialFeatures, LabelEncoder, MinMaxScaler\n",
    ")\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, RFE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression, LinearRegression, Ridge, Lasso,\n",
    "    SGDRegressor, ElasticNet\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, cross_validate,\n",
    "    GridSearchCV, KFold, cross_val_predict\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, mean_squared_error, make_scorer, accuracy_score, log_loss\n",
    ")\n",
    "from sklearn import set_config, datasets\n",
    "from catboost import (\n",
    "    CatBoostRegressor, CatBoostClassifier,\n",
    ")\n",
    "# import category_encoders as ce\n",
    "# from sklearn.pipeline import (\n",
    "#     Pipeline, FeatureUnion, make_pipeline\n",
    "# )\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, StackingClassifier, StackingRegressor,\n",
    "    GradientBoostingRegressor, VotingClassifier, VotingRegressor,\n",
    "    HistGradientBoostingRegressor, GradientBoostingClassifier,\n",
    "    BaggingClassifier, AdaBoostClassifier, RandomForestRegressor,ExtraTreesRegressor\n",
    ")\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "from sklearn.svm import SVC, SVR, LinearSVC\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# from tpot import TPOTClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import math\n",
    "import optuna\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('adidas_match_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 'home_team_result' 무 -> 승,패로 업데이트, 추가적인 기준 필요함\n",
    "# df.loc[(df['home_team_result'] == '무') & (df['home_team_shots_on_target'] >= df['away_team_shots_on_target']), 'home_team_result'] = '승'\n",
    "# df.loc[(df['home_team_result'] == '무') & (df['home_team_shots_on_target'] < df['away_team_shots_on_target']), 'home_team_result'] = '패'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature fun\n",
    "def team_encoding(train):\n",
    "    train['home_win'] = train['home_team_result'].apply(lambda x: 1 if x=='승' else 0) # home_win 열 추가, 승리인 경우 1, 아닌 경우 0\n",
    "    dic = {}\n",
    "    # 각 홈팀별 이긴 경기 수를 딕셔너리에 저장\n",
    "    for team in train['home_team_name'].unique():\n",
    "        value = train[train['home_team_name'] == team]['home_win'].sum() \n",
    "        #home_team_name  열에서 고유한 팀 이름을 가져와 각 팀이 홈에서 이긴 경기 수 계산, 이 값을 dic에 저장\n",
    "        dic[team] = value\n",
    "\n",
    "    label_dic={}\n",
    "    # 승리 횧수를 기준으로 오름차순 정렬, 각 팀에 대해 라벨 부여, 승리 횟수가 적은 팀부터 0,1,2 의 라벨을 부여\n",
    "    for idx, (team, _) in enumerate(sorted(dic.items(), key= lambda x: x[1])):\n",
    "        label_dic[team] = idx\n",
    "    \n",
    "    return label_dic\n",
    "\n",
    "\n",
    "''' 홈팀 득점 이동평균 계산 함수 '''\n",
    "\n",
    "def homeGoal_day_mean(train, test, day):\n",
    "    train[f'home_Goal_{day}_mean'] = -1  # 초기값 -1로 설정\n",
    "    test[f'home_Goal_{day}_mean'] = -1\n",
    "    \n",
    "    teams = train['home_team_name'].unique()\n",
    "    for team in tqdm(teams): # train에서 고유 팀 이름을 가져오고 이를 시각적으로 표시해줌 : tqdm\n",
    "        team_df = train[train['home_team_name'] == team]\n",
    "        # 롤링 윈도우 크기 설정\n",
    "        ch_day = len(team_df) if len(team_df) < day else day # 팀의 경기 수가 주어진 day 보다 적으면, 경기 수 만큼의 윈도우 크기 사용\n",
    "        idx = team_df['home_team_goal_count'].rolling(ch_day).mean().index.values # 롤링 윈도우 평균 계산\n",
    "        val = team_df['home_team_goal_count'].rolling(ch_day).mean().values\n",
    "        train[f'home_Goal_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['home_team_name'] == team].index\n",
    "        test[f'home_Goal_{day}_mean'].loc[test_idx] = val[-1]\n",
    "    # 결측값 처리\n",
    "    train[f'home_Goal_{day}_mean'] = train[f'home_Goal_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "''' 원정팀 득점 이동평균 계산 함수 '''\n",
    "\n",
    "def awayGoal_day_mean(train, test, day):\n",
    "    # 초기값 설정\n",
    "    train[f'away_Goal_{day}_mean'] = -1\n",
    "    test[f'away_Goal_{day}_mean'] = -1\n",
    "    \n",
    "    teams = train['away_team_name'].unique()\n",
    "    for team in tqdm(teams):\n",
    "        team_df = train[train['away_team_name'] == team]\n",
    "        # 롤링 윈도우 크기 설정\n",
    "        ch_day = len(team_df) if len(team_df) < day else day\n",
    "        idx = team_df['away_team_goal_count'].rolling(ch_day).mean().index.values\n",
    "        val = team_df['away_team_goal_count'].rolling(ch_day).mean().values\n",
    "        train[f'away_Goal_{day}_mean'].loc[idx] = val\n",
    "        test_idx = test[test['away_team_name'] == team].index\n",
    "        test[f'away_Goal_{day}_mean'].loc[test_idx] = val[-1]\n",
    "    # 결측값 처리\n",
    "    train[f'away_Goal_{day}_mean'] = train[f'away_Goal_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "# '''홈팀 승리율 평균 계산 함수'''\n",
    "\n",
    "# def homeWin_day_mean(train, test, day):\n",
    "#     train[f'home_winRate_{day}_mean'] = -1\n",
    "#     test[f'home_winRate_{day}_mean'] = -1\n",
    "#     train['win'] = train['home_team_result'].apply(lambda x: 1 if x == '승' else 0)\n",
    "\n",
    "#     teams = train['home_team_name'].unique()\n",
    "#     for team in tqdm(teams):\n",
    "#         team_df = train[train['home_team_name'] == team]\n",
    "#         ch_day = len(team_df) if len(team_df) < day else day\n",
    "#         idx = team_df['win'].rolling(ch_day).mean().index.values\n",
    "#         val = team_df['win'].rolling(ch_day).mean().values\n",
    "#         train[f'home_winRate_{day}_mean'].loc[idx] = val\n",
    "#         test_idx = test[test['home_team_name'] == team].index\n",
    "#         test[f'home_winRate_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "#     train.drop(columns=['win'], inplace=True)\n",
    "\n",
    "#     train[f'home_winRate_{day}_mean'] = train[f'home_winRate_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "# '''원정팀 승리율 평균 계산 함수'''\n",
    "\n",
    "# def awayWin_day_mean(train, test, day):\n",
    "\n",
    "#     train[f'away_winRate_{day}_mean'] = -1\n",
    "#     test[f'away_winRate_{day}_mean'] = -1\n",
    "#     train['win'] = train['home_team_result'].apply(lambda x: 1 if x == '패' else 0)\n",
    "    \n",
    "#     teams = train['away_team_name'].unique()\n",
    "#     for team in tqdm(teams):\n",
    "#         team_df = train[train['away_team_name'] == team]\n",
    "\n",
    "#         ch_day = len(team_df) if len(team_df) < day else day\n",
    "#         idx = team_df['win'].rolling(ch_day).mean().index.values\n",
    "#         val = team_df['win'].rolling(ch_day).mean().values\n",
    "#         train[f'away_winRate_{day}_mean'].loc[idx] = val\n",
    "#         test_idx = test[test['away_team_name'] == team].index\n",
    "#         test[f'away_winRate_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "#     train.drop(columns=['win'], inplace=True)\n",
    "\n",
    "#     train[f'away_winRate_{day}_mean'] = train[f'away_winRate_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''홈팀 평균 계산 함수'''\n",
    "\n",
    "def home_day_mean(train, test, columns, day):\n",
    "    for column in tqdm(columns):\n",
    "        teams = train['home_team_name'].values\n",
    "        train[f'home_{column}_{day}_mean'] = -1\n",
    "        test[f'home_{column}_{day}_mean'] = -1\n",
    "\n",
    "        for team in tqdm(teams):\n",
    "            team_df = train[train['home_team_name'] == team]\n",
    "            idx = team_df[column].rolling(day).mean().index.values\n",
    "            val = team_df[column].rolling(day).mean().values\n",
    "            train[f'home_{column}_{day}_mean'].loc[idx] = val\n",
    "            test_idx = test[test['home_team_name'] == team].index\n",
    "            test[f'home_{column}_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "        train[f'home_{column}_{day}_mean'] = train[f'home_{column}_{day}_mean'].fillna(0)\n",
    "        test[f'home_{column}_{day}_mean'] = test[f'home_{column}_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''원정팀 평균 계산 함수'''\n",
    "\n",
    "def away_day_mean(train, test, columns, day):\n",
    "    for column in tqdm(columns):\n",
    "        teams = train['away_team_name'].values\n",
    "        train[f'away_{column}_{day}_mean'] = -1\n",
    "        test[f'away_{column}_{day}_mean'] = -1\n",
    "\n",
    "        for team in tqdm(teams):\n",
    "            team_df = train[train['away_team_name'] == team]\n",
    "            idx = team_df[column].rolling(day).mean().index.values\n",
    "            val = team_df[column].rolling(day).mean().values\n",
    "            train[f'away_{column}_{day}_mean'].loc[idx] = val\n",
    "            test_idx = test[test['away_team_name'] == team].index\n",
    "            test[f'away_{column}_{day}_mean'].loc[test_idx] = val[-1]\n",
    "\n",
    "        train[f'away_{column}_{day}_mean'] = train[f'away_{column}_{day}_mean'].fillna(0)\n",
    "        test[f'away_{column}_{day}_mean'] = test[f'away_{column}_{day}_mean'].fillna(0)\n",
    "\n",
    "\n",
    "'''전처리 함수'''\n",
    "\n",
    "def preprocessing(train, test):\n",
    "    # 년과 월일로 나누기\n",
    "    train['date_GMT'] = train['date_GMT'].dt.strftime('%Y%m%d')\n",
    "    train['year'] = train['date_GMT'].apply(lambda x : int(x[0:4]))\n",
    "    train['date'] = train['date_GMT'].apply(lambda x : int(x[4:10]))\n",
    "    \n",
    "    test['date_GMT'] = test['date_GMT'].dt.strftime('%Y%m%d')\n",
    "    test['year'] = test['date_GMT'].apply(lambda x : int(x[0:4]))\n",
    "    test['date'] = test['date_GMT'].apply(lambda x : int(x[4:10]))\n",
    "\n",
    "    # train.drop(columns=['date_GMT'], inplace=True)\n",
    "    # test.drop(columns=['date_GMT'], inplace=True)\n",
    "\n",
    "    # # 팀 인코딩 적용   # 위에서 적용 했음\n",
    "    # label_dic = dic\n",
    "    # train['home_team_name'] = train['home_team_name'].apply(lambda x: label_dic[x])\n",
    "    # train['away_team_name'] = train['away_team_name'].apply(lambda x: label_dic[x])\n",
    "    # test['home_team_name'] = test['home_team_name'].apply(lambda x: label_dic[x])\n",
    "    # test['away_team_name'] = test['away_team_name'].apply(lambda x: label_dic[x])\n",
    "\n",
    "    # # 5일간 홈팀 승리 비율 계산    ### 이거 쓰레기인듯\n",
    "    # homeWin_day_mean(train, test, 5)\n",
    "    # # 5일간 원정팀 승리 비율 계산\n",
    "    # awayWin_day_mean(train, test, 5)\n",
    "\n",
    "    # 5일간 홈팀 평균 득점 계산\n",
    "    homeGoal_day_mean(train, test, 5)\n",
    "\n",
    "    # 5일간 원정팀 평균 득점 계산\n",
    "    awayGoal_day_mean(train, test, 5)\n",
    "\n",
    "    # 불필요한 컬럼 제거\n",
    "    train = train.drop(columns=['index','home_team_goal_count','away_team_goal_count','game_points'])\n",
    "    test = test.drop(columns=['index','home_team_goal_count','away_team_goal_count','home_team_result','game_points'])\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_label = {\n",
    "    '승' : 0,\n",
    "    '패' : 1, \n",
    "    '무' : 2,} \n",
    "    \n",
    "X = df.drop(columns=['away_team_possession'])  \n",
    "X['home_team_result'] = X['home_team_result'].map(result_label)\n",
    "y = X['home_team_result']\n",
    "# split_index = 1796 # 2021년도까지의 index\n",
    "# train = X.iloc[:split_index]\n",
    "# test = X.iloc[split_index:]\n",
    "# y_train = y.iloc[:split_index]\n",
    "# y_test = y.iloc[split_index:]\n",
    "\n",
    "# team_name 인코딩\n",
    "cat = ['home_team_name','away_team_name']\n",
    "le = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1, dtype=int)\n",
    "X[cat] = le.fit_transform(X[cat])\n",
    "\n",
    "# # 승무패 인코딩\n",
    "# lec = LabelEncoder()\n",
    "# lec.fit(X['home_team_result'])\n",
    "# y = lec.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 682.50it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 777.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(547, 30) (137, 29)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train,Test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42) ## 이 방법에 의문을 품는 바\n",
    "\n",
    "X_train, X_val= preprocessing(X_train, X_val)\n",
    "X_val_idx = X_val.index.values\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홈팀과 원정팀의 공격 효율성을 계산한 피쳐 생성\n",
    "X_train['home_attack_efficiency'] = X_train['home_Goal_5_mean'] * X_train['home_team_shots_on_target']\n",
    "X_train['away_attack_efficiency'] = X_train['away_Goal_5_mean'] * X_train['away_team_shots_on_target']\n",
    "\n",
    "# 홈팀과 원정팀의 공격 효율성 차이를 나타내는 피쳐 생성\n",
    "X_train['attack_efficiency_difference'] = X_train['home_attack_efficiency'] - X_train['away_attack_efficiency']\n",
    "\n",
    "# 홈팀과 원정팀의 전반 골 수 차이를 나타내는 피쳐 생성\n",
    "X_train['goal_count_diff'] = X_train['home_team_goal_count_half_time'] - X_train['away_team_goal_count_half_time']\n",
    "\n",
    "# 최근 5경기 평균 득점의 표준 편차를 나타내는 피쳐 생성\n",
    "X_train['home_Goal_5_std'] = X_train['home_Goal_5_mean'].rolling(window=5).std()\n",
    "X_train['away_Goal_5_std'] = X_train['away_Goal_5_mean'].rolling(window=5).std()\n",
    "\n",
    "# 결측값을 0으로 대체\n",
    "X_train = X_train.fillna(0)\n",
    "\n",
    "# 테스트 데이터에도 동일한 피쳐 생성\n",
    "X_val['home_attack_efficiency'] = X_val['home_Goal_5_mean'] * X_val['home_team_shots_on_target']\n",
    "X_val['away_attack_efficiency'] = X_val['away_Goal_5_mean'] * X_val['away_team_shots_on_target']\n",
    "X_val['attack_efficiency_difference'] = X_val['home_attack_efficiency'] - X_val['away_attack_efficiency']\n",
    "X_val['goal_count_diff'] = X_val['home_team_goal_count_half_time'] - X_val['away_team_goal_count_half_time']\n",
    "X_val['home_Goal_5_std'] = X_val['home_Goal_5_mean'].rolling(window=5).std()\n",
    "X_val['away_Goal_5_std'] = X_val['away_Goal_5_mean'].rolling(window=5).std()\n",
    "X_val = X_val.fillna(0)\n",
    "\n",
    "# 학습 데이터에서 목표 변수 'home_team_result' 컬럼 제거\n",
    "X_train.drop(columns = ['home_team_result'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "cat = ['home_team_name','away_team_name']\n",
    "\n",
    "num_features = list(set(X_train.columns) - set(cat))\n",
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_val[num_features] = scaler.transform(X_val[num_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled class distribution: Counter({0: 10000, 2: 10000, 1: 10000})\n",
      "Original training set shape: (547, 35)\n",
      "Resampled training set shape: (30000, 35)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# SMOTE 객체 생성 (각 클래스의 샘플 수를 1000개로 설정)\n",
    "smote = SMOTE(sampling_strategy={0: 10000, 1: 10000, 2 : 10000}, random_state=42)\n",
    "\n",
    "# SMOTE-Tomek 객체 생성\n",
    "smote_tomek = SMOTETomek(smote=smote, random_state=42)\n",
    "\n",
    "# 오버샘플링 및 언더샘플링 적용\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "\n",
    "# 각 클래스 비율 확인\n",
    "print(f\"Resampled class distribution: {Counter(y_train_resampled)}\")\n",
    "print(f\"Original training set shape: {X_train.shape}\")\n",
    "print(f\"Resampled training set shape: {X_train_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_resampled['home_team_result'] = y_train_resampled\n",
    "X_val['home_team_result'] = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'home_team_result' 무 -> 승,패로 업데이트, 추가적인 기준 필요함\n",
    "X_train_resampled.loc[(X_train_resampled['home_team_result'] == 2) & (X_train_resampled['home_team_shots_on_target'] >= X_train_resampled['away_team_shots_on_target']), 'home_team_result'] = 0\n",
    "X_train_resampled.loc[(X_train_resampled['home_team_result'] == 2) & (X_train_resampled['home_team_shots_on_target'] < X_train_resampled['away_team_shots_on_target']), 'home_team_result'] = 1\n",
    "# 'home_team_result' 무 -> 승,패로 업데이트, 추가적인 기준 필요함\n",
    "X_val.loc[(X_val['home_team_result'] == 2) & (X_val['home_team_shots_on_target'] >= X_val['away_team_shots_on_target']), 'home_team_result'] = 0\n",
    "X_val.loc[(X_val['home_team_result'] == 2) & (X_val['home_team_shots_on_target'] < X_val['away_team_shots_on_target']), 'home_team_result'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 값 배정\n",
    "y_train_resampled = X_train_resampled['home_team_result']\n",
    "y_val = X_val['home_team_result']\n",
    "# target 값 다시 삭제\n",
    "X_train_resampled.drop(columns='home_team_result', inplace = True)\n",
    "X_val.drop(columns='home_team_result', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pycaret.classification import *\n",
    "\n",
    "# setup_clf = setup(data = X_train, target = y_train, session_id = 42)\n",
    "# model = compare_models(sort = 'Accuracy', fold = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_tune = tune_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(best_tune)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.781021897810219\n",
      "Filtered SHAP Importances:\n",
      "                        column_name  shap_importance\n",
      "7        home_team_shots_on_target         2.288410\n",
      "8        away_team_shots_on_target         1.670785\n",
      "31    attack_efficiency_difference         1.632820\n",
      "22               adidas_point_home         1.182693\n",
      "24                  5_games_result         1.139173\n",
      "32                 goal_count_diff         1.042144\n",
      "23               adidas_point_away         1.014391\n",
      "17  away_team_goal_count_half_time         0.724899\n",
      "5                  home_team_shots         0.361084\n",
      "1                   home_team_name         0.356897\n",
      "14               home_team_offside         0.345118\n",
      "30          away_attack_efficiency         0.316652\n",
      "3           home_team_corner_count         0.315204\n",
      "15               away_team_offside         0.311889\n",
      "11            home_team_possession         0.303585\n",
      "33                 home_Goal_5_std         0.240988\n",
      "29          home_attack_efficiency         0.208749\n",
      "4           away_team_corner_count         0.207466\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import shap\n",
    "SHAP_THRESHOLD = 0.2\n",
    "\n",
    "# feature_names dimension 조정\n",
    "X_train_col = X_train.columns\n",
    "feature_names = X_train_col.to_numpy()\n",
    "\n",
    "# 모델 학습\n",
    "model = xgb.XGBClassifier().fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 모델 예측 및 평가\n",
    "y_pred = model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# SHAP 값 계산\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "# SHAP 값 요약\n",
    "if isinstance(shap_values, list):  # shap_values가 리스트일 경우 (XGBoost >= 1.0.0)\n",
    "    shap_values = shap_values[1]\n",
    "\n",
    "shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame({'column_name': feature_names, 'shap_importance': shap_sum})\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "\n",
    "# 중요도 임계값 적용 (선택 사항)\n",
    "importance_df_filtered = importance_df[importance_df['shap_importance'] > SHAP_THRESHOLD]\n",
    "print(\"Filtered SHAP Importances:\\n\", importance_df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지정된(SHAP_THRESHOLD) Shap feature 중요도 이상인 것만 선택\n",
    "features_selected = importance_df.query('shap_importance > @SHAP_THRESHOLD').column_name.tolist()\n",
    "shap_xgb_X_train_resampled = X_train_resampled[features_selected]\n",
    "shap_xgb_X_val = X_val[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LightGBM 모델 학습\n",
    "# model = lgb.LGBMClassifier().fit(X_train_resampled, y_train_resampled)\n",
    "# SHAP_THRESHOLD = 0.3\n",
    "\n",
    "# # 모델 예측 및 평가\n",
    "# y_pred = model.predict(X_val)\n",
    "# print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "# # SHAP 값 계산\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_val)\n",
    "\n",
    "# shap_sum = np.abs(shap_values).mean(axis=1)[1,:]\n",
    "# importance_df = pd.DataFrame([X_val.columns.tolist(), shap_sum.tolist()]).T\n",
    "# importance_df.columns = ['column_name', 'shap_importance']\n",
    "# importance_df = importance_df.sort_values('shap_importance', ascending=False);\n",
    "# importance_df\n",
    "\n",
    "# # SHAP 값 데이터프레임 생성 (각 피쳐별 SHAP 값)\n",
    "# shap_values_df = pd.DataFrame(shap_values[1], columns=X_val.columns)\n",
    "# shap_values_df\n",
    "\n",
    "# # SHAP 값의 평균 절대값 계산\n",
    "# shap_abs_mean = pd.DataFrame(shap_values[1], columns=X_val.columns).abs().mean().sort_values(ascending=False)\n",
    "\n",
    "# # SHAP 값 평균 절대값 시각화\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# shap_abs_mean.plot(kind='barh')\n",
    "# plt.title(\"Mean Absolute SHAP Values for Features\")\n",
    "# plt.xlabel(\"Mean Absolute SHAP Value\")\n",
    "# plt.ylabel(\"Features\")\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 지정된(SHAP_THRESHOLD) Shap feature 중요도 이상인 것만 선택\n",
    "# features_selected = importance_df.query('shap_importance > @SHAP_THRESHOLD').column_name.tolist()\n",
    "# shap_lgbm_X_train_resampled = X_train_resampled[features_selected]\n",
    "# shap_lgbm_X_val = X_val[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oputna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgboostclassifier\n",
    "# import optuna\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# def xgb_objective(trial):\n",
    "#     # 하이퍼파라미터 범위 설정\n",
    "#     max_depth = trial.suggest_int('max_depth', 3, 7)  # max_depth의 범위를 줄임\n",
    "#     learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "#     n_estimators = trial.suggest_int('n_estimators', 50, 200)  # n_estimators의 범위를 줄임\n",
    "#     subsample = trial.suggest_float('subsample', 0.5, 0.9)\n",
    "#     colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 0.9)\n",
    "#     min_child_weight = trial.suggest_int('min_child_weight', 4, 10)  # 추가\n",
    "#     gamma = trial.suggest_float('gamma', 0, 5)  # 추가\n",
    "    \n",
    "#     # XGBClassifier 모델 정의\n",
    "#     clf = XGBClassifier(\n",
    "#         max_depth=max_depth,\n",
    "#         learning_rate=learning_rate,\n",
    "#         n_estimators=n_estimators,\n",
    "#         subsample=subsample,\n",
    "#         colsample_bytree=colsample_bytree,\n",
    "#         min_child_weight=min_child_weight,  # 추가\n",
    "#         gamma=gamma,  # 추가\n",
    "#         use_label_encoder=False,\n",
    "#         eval_metric='logloss'\n",
    "#     )\n",
    "    \n",
    "#     # 교차 검증 점수 계산\n",
    "#     scores = cross_val_score(clf, shap_xgb_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "#     return scores.mean()\n",
    "\n",
    "# # Optuna 스터디 생성 및 최적화\n",
    "# xgb_study = optuna.create_study(direction='maximize')\n",
    "# xgb_study.optimize(xgb_objective, n_trials=50)  # 최적화 반복 횟수는 필요에 따라 조절\n",
    "\n",
    "# # 최적 하이퍼파라미터 출력\n",
    "# xgb_best_params = xgb_study.best_params\n",
    "# print(' ')\n",
    "# print(xgb_study.best_value)\n",
    "# print(xgb_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_logis=xgb.XGBClassifier(**xgb_best_params)\n",
    "# # model_logis=xgb.XGBClassifier(max_depth= 4, learning_rate= 0.00020353095689003422, n_estimators= 229, subsample= 0.5217582675029752, colsample_bytree= 0.5421399627551824)\n",
    "# model_logis.fit(shap_xgb_X_train_resampled, y_train_resampled)\n",
    "# y_pred = model_logis.predict(shap_xgb_X_val)\n",
    "\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy=\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LogisticRegression\n",
    "# def logreg_objective(trial):\n",
    "\n",
    "#     r = trial.suggest_float('l1_ratio', 0.3, 0.8, log=False)  # 범위를 0.1에서 0.9로 좁힘\n",
    "#     c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "#     max_iter = trial.suggest_int('max_iter', 500, 2000, step=500)  # max_iter 튜닝 추가\n",
    "    \n",
    "#     clf =  LogisticRegression(max_iter=max_iter, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "#     scores = cross_val_score(clf, X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "#     return scores.mean()\n",
    "    \n",
    "# logreg_study = optuna.create_study(direction='maximize')\n",
    "# logreg_study.optimize(logreg_objective, n_trials=20)\n",
    "\n",
    "# logreg_best_params = logreg_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_logis=LogisticRegression(**logreg_best_params)\n",
    "# model_logis.fit(X_train_resampled,y_train_resampled)\n",
    "# y_pred = model_logis.predict(X_val)\n",
    "\n",
    "# accuracy = accuracy_score(y_val, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-22 19:36:49,780] A new study created in memory with name: no-name-76b3a332-f854-40ae-acc9-ac8e0a7c9ee5\n",
      "[I 2024-07-22 19:36:49,889] Trial 0 finished with value: 0.9093562977540598 and parameters: {'alpha': 411.92417788604325}. Best is trial 0 with value: 0.9093562977540598.\n",
      "[I 2024-07-22 19:36:49,975] Trial 1 finished with value: 0.9094820578910131 and parameters: {'alpha': 1.218050078623465e-05}. Best is trial 1 with value: 0.9094820578910131.\n",
      "[I 2024-07-22 19:36:50,063] Trial 2 finished with value: 0.9094821380270393 and parameters: {'alpha': 0.3719413889883221}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,146] Trial 3 finished with value: 0.9094717737676642 and parameters: {'alpha': 33.91972157814271}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,234] Trial 4 finished with value: 0.9094820578910131 and parameters: {'alpha': 2.1782361327600228e-05}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,319] Trial 5 finished with value: 0.9093425410695798 and parameters: {'alpha': 445.186978966699}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,405] Trial 6 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.00164946822941957}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,488] Trial 7 finished with value: 0.9094203264389105 and parameters: {'alpha': 231.32320789425097}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,570] Trial 8 finished with value: 0.909481363378787 and parameters: {'alpha': 1.5908674775971547}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,656] Trial 9 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.0013377015772972828}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,746] Trial 10 finished with value: 0.9094819777549871 and parameters: {'alpha': 0.16151208227832664}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,833] Trial 11 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.0069756818844626985}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:50,920] Trial 12 finished with value: 0.9094820578910131 and parameters: {'alpha': 1.509351439244255e-05}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,007] Trial 13 finished with value: 0.9094812298187435 and parameters: {'alpha': 1.6478727190723563}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,094] Trial 14 finished with value: 0.9094819510429782 and parameters: {'alpha': 0.04029262585091206}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,189] Trial 15 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.0001559748694949403}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,272] Trial 16 finished with value: 0.9094808024266045 and parameters: {'alpha': 2.6604598848519334}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,357] Trial 17 finished with value: 0.9094819243309696 and parameters: {'alpha': 0.13309488004416545}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,441] Trial 18 finished with value: 0.9094786120418911 and parameters: {'alpha': 15.641843062369892}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,528] Trial 19 finished with value: 0.9094819510429785 and parameters: {'alpha': 0.015190136232735428}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,612] Trial 20 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.0002103353180537476}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,700] Trial 21 finished with value: 0.9094820578910131 and parameters: {'alpha': 1.0996592410523524e-05}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,788] Trial 22 finished with value: 0.9094820311790044 and parameters: {'alpha': 8.765921626005005e-05}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,875] Trial 23 finished with value: 0.9094820578910131 and parameters: {'alpha': 3.825381443822415e-05}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:51,959] Trial 24 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.0006615893898784754}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:52,050] Trial 25 finished with value: 0.9094820846030219 and parameters: {'alpha': 0.3000207656944739}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:52,133] Trial 26 finished with value: 0.9094821380270391 and parameters: {'alpha': 0.3587115825851712}. Best is trial 2 with value: 0.9094821380270393.\n",
      "[I 2024-07-22 19:36:52,229] Trial 27 finished with value: 0.9094822181630654 and parameters: {'alpha': 0.5438927106776532}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:52,312] Trial 28 finished with value: 0.9094820578910133 and parameters: {'alpha': 0.7858870913127272}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:52,398] Trial 29 finished with value: 0.909479947642326 and parameters: {'alpha': 10.421569669316131}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:52,482] Trial 30 finished with value: 0.9094819777549871 and parameters: {'alpha': 0.03557067928792351}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:52,565] Trial 31 finished with value: 0.9094821380270393 and parameters: {'alpha': 0.3656872743388909}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:52,649] Trial 32 finished with value: 0.9094821914510568 and parameters: {'alpha': 0.4345486695145966}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:52,734] Trial 33 finished with value: 0.9094809894106654 and parameters: {'alpha': 6.350151604079566}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:52,822] Trial 34 finished with value: 0.9094595930916977 and parameters: {'alpha': 83.26090164633003}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:52,907] Trial 35 finished with value: 0.9094821380270393 and parameters: {'alpha': 0.4711615203239878}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:52,993] Trial 36 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.04989599643120127}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,076] Trial 37 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.0070462938700788}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,165] Trial 38 finished with value: 0.9094810428346826 and parameters: {'alpha': 3.8103080944219148}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,255] Trial 39 finished with value: 0.9094819510429782 and parameters: {'alpha': 0.09197686581428628}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,342] Trial 40 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.8493334236215017}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,427] Trial 41 finished with value: 0.9094821647390479 and parameters: {'alpha': 0.3614141610994966}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,512] Trial 42 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.24044360097115997}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,596] Trial 43 finished with value: 0.9094820578910131 and parameters: {'alpha': 0.814851179917906}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,683] Trial 44 finished with value: 0.9094757271449515 and parameters: {'alpha': 26.430179833514323}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,769] Trial 45 finished with value: 0.9094819510429782 and parameters: {'alpha': 0.09209113720026527}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,857] Trial 46 finished with value: 0.9094809359866479 and parameters: {'alpha': 2.3673736035502175}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:53,951] Trial 47 finished with value: 0.9094820044669957 and parameters: {'alpha': 0.012930437701749346}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:54,043] Trial 48 finished with value: 0.9094820578910131 and parameters: {'alpha': 0.8640898186944973}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:54,132] Trial 49 finished with value: 0.9094819243309696 and parameters: {'alpha': 0.05757052734391602}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:54,234] Trial 50 finished with value: 0.9094811496827173 and parameters: {'alpha': 4.772801234147984}. Best is trial 27 with value: 0.9094822181630654.\n",
      "[I 2024-07-22 19:36:54,317] Trial 51 finished with value: 0.9094822715870827 and parameters: {'alpha': 0.5208191171297608}. Best is trial 51 with value: 0.9094822715870827.\n",
      "[I 2024-07-22 19:36:54,408] Trial 52 finished with value: 0.9094812031067349 and parameters: {'alpha': 1.698092271861281}. Best is trial 51 with value: 0.9094822715870827.\n",
      "[I 2024-07-22 19:36:54,496] Trial 53 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.20487403008052488}. Best is trial 51 with value: 0.9094822715870827.\n",
      "[I 2024-07-22 19:36:54,586] Trial 54 finished with value: 0.9094823784351176 and parameters: {'alpha': 0.6013740228212457}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:54,674] Trial 55 finished with value: 0.9091548624964627 and parameters: {'alpha': 872.4042526407061}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:54,765] Trial 56 finished with value: 0.9094819777549871 and parameters: {'alpha': 0.023262299106399997}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:54,859] Trial 57 finished with value: 0.9094817907709262 and parameters: {'alpha': 1.2690723060788258}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:54,950] Trial 58 finished with value: 0.9094819243309696 and parameters: {'alpha': 0.13385434238949093}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,038] Trial 59 finished with value: 0.9094822181630654 and parameters: {'alpha': 0.4258253819397506}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,122] Trial 60 finished with value: 0.909480749002587 and parameters: {'alpha': 8.724126088292447}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,219] Trial 61 finished with value: 0.9094822715870827 and parameters: {'alpha': 0.5186116982964548}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,306] Trial 62 finished with value: 0.9094822448750741 and parameters: {'alpha': 0.671638879592229}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,389] Trial 63 finished with value: 0.9094822715870827 and parameters: {'alpha': 0.5202444518856124}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,474] Trial 64 finished with value: 0.9094808024266042 and parameters: {'alpha': 2.5552487135050077}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,557] Trial 65 finished with value: 0.9094822448750741 and parameters: {'alpha': 0.6757455287005698}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,641] Trial 66 finished with value: 0.9094818441949437 and parameters: {'alpha': 1.152992870395609}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,727] Trial 67 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.15708396794643395}. Best is trial 54 with value: 0.9094823784351176.\n",
      "[I 2024-07-22 19:36:55,818] Trial 68 finished with value: 0.9094824051471263 and parameters: {'alpha': 0.5937975444801888}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:55,911] Trial 69 finished with value: 0.9094806955785696 and parameters: {'alpha': 3.2408275643646767}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:55,997] Trial 70 finished with value: 0.9094776236975693 and parameters: {'alpha': 20.493616586692724}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,082] Trial 71 finished with value: 0.9094823517231089 and parameters: {'alpha': 0.6154522207512215}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,178] Trial 72 finished with value: 0.9094813900907958 and parameters: {'alpha': 1.7477347575560607}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,264] Trial 73 finished with value: 0.9094824051471262 and parameters: {'alpha': 0.5885355271031338}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,348] Trial 74 finished with value: 0.9094819777549871 and parameters: {'alpha': 0.07152701641867021}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,435] Trial 75 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.22597815222952009}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,519] Trial 76 finished with value: 0.9094815770748567 and parameters: {'alpha': 1.235037755965822}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,606] Trial 77 finished with value: 0.9094651224774982 and parameters: {'alpha': 69.97985927585901}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,692] Trial 78 finished with value: 0.9094809092746391 and parameters: {'alpha': 6.383791403437394}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,783] Trial 79 finished with value: 0.9094823784351176 and parameters: {'alpha': 0.5840854472319739}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,877] Trial 80 finished with value: 0.9094819243309696 and parameters: {'alpha': 0.13194677475006644}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:56,964] Trial 81 finished with value: 0.9094823250111 and parameters: {'alpha': 0.635433520770047}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,062] Trial 82 finished with value: 0.9094820311790045 and parameters: {'alpha': 0.2588398513937746}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,154] Trial 83 finished with value: 0.9094822181630654 and parameters: {'alpha': 0.5341135299299268}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,256] Trial 84 finished with value: 0.9094813633787869 and parameters: {'alpha': 1.8102209989309854}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,347] Trial 85 finished with value: 0.9094818709069523 and parameters: {'alpha': 0.9614613879226684}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,436] Trial 86 finished with value: 0.9094821380270391 and parameters: {'alpha': 0.38175318101059064}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,527] Trial 87 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.19645653554208453}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,615] Trial 88 finished with value: 0.9094818709069523 and parameters: {'alpha': 0.10206311522721605}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,702] Trial 89 finished with value: 0.9094815503628478 and parameters: {'alpha': 4.299798540794288}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,786] Trial 90 finished with value: 0.9094820846030219 and parameters: {'alpha': 0.29532736364291945}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,871] Trial 91 finished with value: 0.9094823784351176 and parameters: {'alpha': 0.6080752623701778}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:57,955] Trial 92 finished with value: 0.9094822982990913 and parameters: {'alpha': 0.6442752826627371}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,043] Trial 93 finished with value: 0.9094807222905782 and parameters: {'alpha': 2.1288931977363674}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,128] Trial 94 finished with value: 0.9094814969388305 and parameters: {'alpha': 1.3584100944488142}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,231] Trial 95 finished with value: 0.9094823250111 and parameters: {'alpha': 0.633532778140047}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,314] Trial 96 finished with value: 0.9094819777549871 and parameters: {'alpha': 0.035022795913819585}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,395] Trial 97 finished with value: 0.9094820578910131 and parameters: {'alpha': 0.8704912418115}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,478] Trial 98 finished with value: 0.9094807757145956 and parameters: {'alpha': 2.697605268135252}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,561] Trial 99 finished with value: 0.9094821380270393 and parameters: {'alpha': 0.3102068320043162}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,650] Trial 100 finished with value: 0.9094795469621956 and parameters: {'alpha': 11.553007945486243}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,736] Trial 101 finished with value: 0.9094824051471262 and parameters: {'alpha': 0.5888126793928231}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,822] Trial 102 finished with value: 0.9094823784351176 and parameters: {'alpha': 0.7016015334301011}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,905] Trial 103 finished with value: 0.9094817373469087 and parameters: {'alpha': 1.0728518789496255}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:58,993] Trial 104 finished with value: 0.9094824051471263 and parameters: {'alpha': 0.5942797412913116}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,077] Trial 105 finished with value: 0.9094819510429785 and parameters: {'alpha': 0.1272440623816299}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,171] Trial 106 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.23033144457132135}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,265] Trial 107 finished with value: 0.909481363378787 and parameters: {'alpha': 1.591666817172104}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,348] Trial 108 finished with value: 0.9094820846030217 and parameters: {'alpha': 0.34564636626567274}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,430] Trial 109 finished with value: 0.9094820578910131 and parameters: {'alpha': 0.7581428980189328}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,518] Trial 110 finished with value: 0.9094812031067349 and parameters: {'alpha': 5.884970323329476}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,602] Trial 111 finished with value: 0.9094824051471263 and parameters: {'alpha': 0.5957102084063696}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,685] Trial 112 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.18353017897104695}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,770] Trial 113 finished with value: 0.9094817106349001 and parameters: {'alpha': 1.0513365285135727}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,853] Trial 114 finished with value: 0.9094808024266045 and parameters: {'alpha': 3.3440022252270456}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:36:59,937] Trial 115 finished with value: 0.909482164739048 and parameters: {'alpha': 0.4403210390145185}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,022] Trial 116 finished with value: 0.9094822181630654 and parameters: {'alpha': 0.668665333936501}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,111] Trial 117 finished with value: 0.9094819510429785 and parameters: {'alpha': 0.08549170838695495}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,209] Trial 118 finished with value: 0.9094815770748567 and parameters: {'alpha': 1.3516893230640088}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,293] Trial 119 finished with value: 0.9094807757145956 and parameters: {'alpha': 2.1532408504949503}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,376] Trial 120 finished with value: 0.9094821113150305 and parameters: {'alpha': 0.33320082082216174}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,461] Trial 121 finished with value: 0.9094822181630654 and parameters: {'alpha': 0.5359663917714397}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,549] Trial 122 finished with value: 0.9094822448750741 and parameters: {'alpha': 0.673746420686807}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,636] Trial 123 finished with value: 0.9094819777549871 and parameters: {'alpha': 0.16138581294049545}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,723] Trial 124 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.8870026002674054}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,810] Trial 125 finished with value: 0.9094822715870827 and parameters: {'alpha': 0.5020926075774613}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,895] Trial 126 finished with value: 0.9094820578910131 and parameters: {'alpha': 0.25167439379648393}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:00,979] Trial 127 finished with value: 0.9094815770748567 and parameters: {'alpha': 1.3372401233858913}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,062] Trial 128 finished with value: 0.9094821914510566 and parameters: {'alpha': 0.35326096983519684}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,147] Trial 129 finished with value: 0.909482351723109 and parameters: {'alpha': 0.7024306630365924}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,243] Trial 130 finished with value: 0.9094810695466914 and parameters: {'alpha': 1.9317220923357332}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,327] Trial 131 finished with value: 0.9094822448750741 and parameters: {'alpha': 0.7151018589795204}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,415] Trial 132 finished with value: 0.909482351723109 and parameters: {'alpha': 0.5808488550421216}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,497] Trial 133 finished with value: 0.9094819777549872 and parameters: {'alpha': 0.9374116713736718}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,582] Trial 134 finished with value: 0.9094821914510566 and parameters: {'alpha': 0.4679713832523336}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,664] Trial 135 finished with value: 0.9094820578910133 and parameters: {'alpha': 0.2582462685127857}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,747] Trial 136 finished with value: 0.9094806154425434 and parameters: {'alpha': 3.219447349617505}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,830] Trial 137 finished with value: 0.9094818441949437 and parameters: {'alpha': 1.151763939702696}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,912] Trial 138 finished with value: 0.9094820578910131 and parameters: {'alpha': 0.0024374773429446514}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:01,995] Trial 139 finished with value: 0.9094821113150305 and parameters: {'alpha': 0.3982158738134368}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,080] Trial 140 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.17456062618757412}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,171] Trial 141 finished with value: 0.9094822448750741 and parameters: {'alpha': 0.6778943706345467}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,258] Trial 142 finished with value: 0.9094823250111 and parameters: {'alpha': 0.6290685267797872}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,342] Trial 143 finished with value: 0.9094815236508391 and parameters: {'alpha': 1.3712174047191863}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,425] Trial 144 finished with value: 0.9094822982990913 and parameters: {'alpha': 0.5035728133305523}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,508] Trial 145 finished with value: 0.9094821113150307 and parameters: {'alpha': 0.8812379408453849}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,589] Trial 146 finished with value: 0.9094821113150305 and parameters: {'alpha': 0.31196097317903404}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,674] Trial 147 finished with value: 0.9094811229707088 and parameters: {'alpha': 1.8888682668099923}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,767] Trial 148 finished with value: 0.9094818976189609 and parameters: {'alpha': 0.11264440381700555}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,850] Trial 149 finished with value: 0.9094822982990913 and parameters: {'alpha': 0.6403333587304314}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:02,934] Trial 150 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.22602953119271635}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,018] Trial 151 finished with value: 0.9094823250111 and parameters: {'alpha': 0.6299997018029931}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,098] Trial 152 finished with value: 0.9094820578910131 and parameters: {'alpha': 0.3945333397141818}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,193] Trial 153 finished with value: 0.9094817106349001 and parameters: {'alpha': 1.0302289621896652}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,275] Trial 154 finished with value: 0.9094822982990914 and parameters: {'alpha': 0.5692409631760711}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,358] Trial 155 finished with value: 0.909481470226822 and parameters: {'alpha': 1.5333921788809703}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,442] Trial 156 finished with value: 0.9094820846030217 and parameters: {'alpha': 0.8799478611921765}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,529] Trial 157 finished with value: 0.9094820578910131 and parameters: {'alpha': 0.3947976924205085}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,613] Trial 158 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.24715268731027107}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,696] Trial 159 finished with value: 0.9094823784351175 and parameters: {'alpha': 0.6164058230195115}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,780] Trial 160 finished with value: 0.909480749002587 and parameters: {'alpha': 2.774080385024644}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,866] Trial 161 finished with value: 0.9094823517231087 and parameters: {'alpha': 0.6204866601262284}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:03,951] Trial 162 finished with value: 0.9094818441949436 and parameters: {'alpha': 1.1144009106065131}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,036] Trial 163 finished with value: 0.9094821914510568 and parameters: {'alpha': 0.4346056293494403}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,120] Trial 164 finished with value: 0.9094820846030217 and parameters: {'alpha': 0.877686471462331}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,215] Trial 165 finished with value: 0.9094820846030219 and parameters: {'alpha': 0.30323611407007217}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,298] Trial 166 finished with value: 0.9094822715870827 and parameters: {'alpha': 0.5647107424140159}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,379] Trial 167 finished with value: 0.9094816572108827 and parameters: {'alpha': 1.447156585554903}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,464] Trial 168 finished with value: 0.9094821647390479 and parameters: {'alpha': 0.7389424684755361}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,546] Trial 169 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.17233513314929308}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,629] Trial 170 finished with value: 0.9094807222905782 and parameters: {'alpha': 2.134255923957589}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,713] Trial 171 finished with value: 0.9094822181630654 and parameters: {'alpha': 0.646202898214865}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,797] Trial 172 finished with value: 0.909482164739048 and parameters: {'alpha': 0.44085642694902283}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,879] Trial 173 finished with value: 0.9094820846030217 and parameters: {'alpha': 0.3150764869829541}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:04,961] Trial 174 finished with value: 0.9094817640589175 and parameters: {'alpha': 1.1336181159949656}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,049] Trial 175 finished with value: 0.9094823250111 and parameters: {'alpha': 0.629756448571181}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,131] Trial 176 finished with value: 0.9094820044669957 and parameters: {'alpha': 0.8568349281191517}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,227] Trial 177 finished with value: 0.9094822982990917 and parameters: {'alpha': 0.5092416486399087}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,313] Trial 178 finished with value: 0.9094820311790044 and parameters: {'alpha': 0.2455018999128191}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,398] Trial 179 finished with value: 0.909481363378787 and parameters: {'alpha': 1.5932133447811998}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,484] Trial 180 finished with value: 0.909482164739048 and parameters: {'alpha': 0.4429440515884611}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,573] Trial 181 finished with value: 0.9094821914510568 and parameters: {'alpha': 0.7294388304354321}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,663] Trial 182 finished with value: 0.9094823250111 and parameters: {'alpha': 0.6319654204734793}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,751] Trial 183 finished with value: 0.9094816839228913 and parameters: {'alpha': 1.0489794863854136}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,837] Trial 184 finished with value: 0.9094821113150305 and parameters: {'alpha': 0.3882545978454532}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:05,922] Trial 185 finished with value: 0.9094822448750741 and parameters: {'alpha': 0.5594027020503952}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,008] Trial 186 finished with value: 0.9094821914510568 and parameters: {'alpha': 0.7283307773920068}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,096] Trial 187 finished with value: 0.9094820846030219 and parameters: {'alpha': 0.3033125757136124}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,192] Trial 188 finished with value: 0.9094818441949436 and parameters: {'alpha': 1.1829222420669583}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,278] Trial 189 finished with value: 0.9094822181630654 and parameters: {'alpha': 0.5455600656568561}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,363] Trial 190 finished with value: 0.9094820044669958 and parameters: {'alpha': 0.16583412985510268}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,444] Trial 191 finished with value: 0.9094821647390479 and parameters: {'alpha': 0.7389253883339644}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,527] Trial 192 finished with value: 0.9094823784351176 and parameters: {'alpha': 0.6086438039083844}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,611] Trial 193 finished with value: 0.909482164739048 and parameters: {'alpha': 0.4012556778319894}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,693] Trial 194 finished with value: 0.9094818709069523 and parameters: {'alpha': 0.9611478445394364}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,775] Trial 195 finished with value: 0.9094812565307522 and parameters: {'alpha': 1.609322540495141}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,858] Trial 196 finished with value: 0.9094820578910131 and parameters: {'alpha': 0.34184925449609627}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:06,939] Trial 197 finished with value: 0.9094822715870827 and parameters: {'alpha': 0.5644749948605867}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:07,020] Trial 198 finished with value: 0.9094820578910133 and parameters: {'alpha': 0.2233625565754678}. Best is trial 68 with value: 0.9094824051471263.\n",
      "[I 2024-07-22 19:37:07,107] Trial 199 finished with value: 0.9094818174829348 and parameters: {'alpha': 0.9776549666442766}. Best is trial 68 with value: 0.9094824051471263.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Ridge Classifier의 목적 함수\n",
    "def ridge_classifier_objective(trial):\n",
    "\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e3, log=True)\n",
    "    clf = RidgeClassifier(alpha=alpha)\n",
    "    \n",
    "    # 교차 검증을 통한 모델 평가 (AUC 스코어)\n",
    "    # 다중 클래스의 경우, 'ovr' 또는 'ovo' 스키마를 사용\n",
    "    # if len(set(y_train_resampled)) > 2:\n",
    "    #     scoring = 'roc_auc_ovr'\n",
    "    # else:\n",
    "    #     scoring = 'roc_auc'\n",
    "    \n",
    "    scores = cross_val_score(clf, shap_xgb_X_train_resampled, y_train_resampled, cv=6, scoring='roc_auc')\n",
    "    return scores.mean()\n",
    "\n",
    "ridge_classifier_study = optuna.create_study(direction='maximize')\n",
    "ridge_classifier_study.optimize(ridge_classifier_objective, n_trials=200)\n",
    "ridge_classifier_best_params = ridge_classifier_study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7956204379562044\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터로 최종 모델 학습 및 평가\n",
    "model_ridge_classifier = RidgeClassifier(**ridge_classifier_best_params)\n",
    "model_ridge_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 검증 데이터로 예측\n",
    "y_pred = model_ridge_classifier.predict(X_val)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9112249253094322\n"
     ]
    }
   ],
   "source": [
    "# 최적의 하이퍼파라미터로 최종 모델 학습 및 평가\n",
    "model_ridge_classifier = RidgeClassifier(**ridge_classifier_best_params)\n",
    "model_ridge_classifier.fit(shap_xgb_X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 검증 데이터로 예측\n",
    "y_pred = model_ridge_classifier.predict(shap_xgb_X_val)\n",
    "y_pred_proba = model_ridge_classifier.decision_function(shap_xgb_X_val)\n",
    "\n",
    "# 다중 클래스의 경우 ROC AUC 스코어 계산\n",
    "if len(set(y_val)) > 2:\n",
    "    y_val_bin = label_binarize(y_val, classes=list(set(y_val)))\n",
    "    auc_score = roc_auc_score(y_val_bin, y_pred_proba, multi_class='ovr')\n",
    "else:\n",
    "    auc_score = roc_auc_score(y_val, y_pred_proba)\n",
    "\n",
    "print(\"AUC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis=LogisticRegression(l1_ratio= 0.789370019111903, C= 0.07701480047825814, max_iter= 1000)\n",
    "model_logis.fit(X_train_resampled,y_train_resampled)\n",
    "y_pred = model_logis.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomforest feature selection  큰 효과가 없는 듯 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestClassifier()\n",
    "# model.fit(train_resampled, y_train_resampled)\n",
    "# y_pred = model.predict(test)\n",
    "\n",
    "# rn_features = []\n",
    "# importances = model.feature_importances_\n",
    "# feature_names = train.columns\n",
    "\n",
    "# # 피처 중요도를 기준으로 정렬하여 상위 피처 선택\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# # 중요도가 0.01 이상인 피처만 선택\n",
    "# # top_number = 40\n",
    "# top_num_indices = [idx for idx in indices if importances[idx] >= 0.005] #[:top_number]\n",
    "# top_features = feature_names[top_num_indices]\n",
    "\n",
    "# for i, feature in enumerate(top_features):\n",
    "#     print(f\"{i+1}. {feature} (중요도: {importances[top_num_indices[i]]})\")\n",
    "#     rn_features.append(feature)\n",
    "\n",
    "# rn_train_resampled = train_resampled[rn_features]\n",
    "# rn_test = test[rn_features]\n",
    "\n",
    "# model_logis=LogisticRegression(**logreg_best_params)\n",
    "# model_logis.fit(rn_train_resampled,y_train_resampled)\n",
    "# y_pred = model_logis.predict(rn_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상관계수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "corr_number = 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > corr_number)]\n",
    "to_drop\n",
    "# # 특징 제거\n",
    "corr_X_train_resampled = X_train_resampled.drop(columns=to_drop)  \n",
    "corr_X_val = X_val.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_objective(trial):\n",
    "    \n",
    "    r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "     \n",
    "    clf =  LogisticRegression(max_iter=5000, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "    scores = cross_val_score(clf, corr_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "logreg_study = optuna.create_study(direction='maximize')\n",
    "logreg_study.optimize(logreg_objective, n_trials=5)\n",
    "\n",
    "logreg_best_params = logreg_study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis=LogisticRegression(**logreg_best_params)\n",
    "model_logis.fit(corr_X_train_resampled,y_train_resampled)\n",
    "y_pred = model_logis.predict(corr_X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 규제(Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha 값 후보군 설정\n",
    "alpha_values = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 1, 10, 100]\n",
    "param_grid = {'alpha': alpha_values}\n",
    "\n",
    "# Lasso 모델과 GridSearchCV 설정\n",
    "lasso = Lasso()\n",
    "grid_search = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# 최적의 alpha 값 찾기\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=best_alpha)  # 위에서 나온 alpha 값으로 조정한 거임\n",
    "lasso.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 가중치가 0이 아닌 특징 선택\n",
    "selected_features = X_train_resampled.columns[lasso.coef_ != 0]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1_X_train_resampled = X_train_resampled[selected_features]\n",
    "L1_X_val = X_val[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_objective(trial):\n",
    "    \n",
    "    r = trial.suggest_float('l1_ratio', 0, 1, log=False)\n",
    "    c = trial.suggest_float('C', 1e-4, 1e2, log=True)\n",
    "     \n",
    "    clf =  LogisticRegression(max_iter=5000, solver='saga', penalty='elasticnet', l1_ratio=r, C=c)\n",
    "    scores = cross_val_score(clf, L1_X_train_resampled, y_train_resampled, cv=5, scoring='accuracy')\n",
    "    \n",
    "    return scores.mean()\n",
    "    \n",
    "logreg_study = optuna.create_study(direction='maximize')\n",
    "logreg_study.optimize(logreg_objective, n_trials=5)\n",
    "\n",
    "logreg_best_params = logreg_study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2013~2023  \n",
    "### 많긴 하지만 정확도 떨어질 것으로 예상됨\n",
    "\n",
    "# 2020~2023\n",
    "### 데이터 수가 급격히 줄어듬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
